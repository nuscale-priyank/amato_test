# ğŸš€ AMATO Production Data Science Platform

A comprehensive data science platform for customer analytics, featuring data pipelines, ML pipelines, and model development across multiple databases.

## ğŸ“‹ Overview

AMATO Production is a multi-database data science platform that processes customer data from MySQL, PostgreSQL, and MongoDB to generate insights through machine learning models.

### ğŸ¯ Key Features

- **Multi-Database Architecture**: MySQL (Customer/Transaction), PostgreSQL (Campaign/A/B Tests), MongoDB (Clickstream)
- **Data Pipelines**: SQL transformations using Trino, unified dataset creation
- **ML Pipelines**: Customer Segmentation, Forecasting, Journey Simulation, Campaign Optimization
- **Real-time Inference**: FastAPI endpoints for model predictions
- **Interactive Dashboard**: Streamlit application for data exploration and pipeline execution

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     MySQL       â”‚    â”‚   PostgreSQL    â”‚    â”‚     MongoDB     â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ Customers     â”‚    â”‚ â€¢ Campaigns     â”‚    â”‚ â€¢ Sessions      â”‚
â”‚ â€¢ Transactions  â”‚    â”‚ â€¢ A/B Tests     â”‚    â”‚ â€¢ Page Views    â”‚
â”‚ â€¢ Demographics  â”‚    â”‚ â€¢ Performance   â”‚    â”‚ â€¢ Events        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚     Trino       â”‚
                    â”‚                 â”‚
                    â”‚ â€¢ SQL Queries   â”‚
                    â”‚ â€¢ Data Joins    â”‚
                    â”‚ â€¢ Transformationsâ”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Data Pipelines â”‚
                    â”‚                 â”‚
                    â”‚ â€¢ RFM Analysis  â”‚
                    â”‚ â€¢ Journey Data  â”‚
                    â”‚ â€¢ Performance   â”‚
                    â”‚ â€¢ A/B Results   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  ML Pipelines   â”‚
                    â”‚                 â”‚
                    â”‚ â€¢ Segmentation  â”‚
                    â”‚ â€¢ Forecasting   â”‚
                    â”‚ â€¢ Simulation    â”‚
                    â”‚ â€¢ Optimization  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   FastAPI       â”‚
                    â”‚                 â”‚
                    â”‚ â€¢ Real-time     â”‚
                    â”‚ â€¢ Batch         â”‚
                    â”‚ â€¢ Inference     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
amato_production/
â”œâ”€â”€ ddl/                          # Database schema files
â”‚   â”œâ”€â”€ mysql_schema.sql         # MySQL DDL
â”‚   â”œâ”€â”€ postgresql_schema.sql    # PostgreSQL DDL
â”‚   â””â”€â”€ mongodb_schema.js        # MongoDB schema
â”œâ”€â”€ data_generation/             # Data generation scripts
â”‚   â”œâ”€â”€ mysql_data_generator.py
â”‚   â”œâ”€â”€ postgresql_data_generator.py
â”‚   â”œâ”€â”€ mongodb_data_generator.py
â”‚   â””â”€â”€ generate_all_data.py
â”œâ”€â”€ data_pipelines/              # Data transformation pipelines
â”‚   â”œâ”€â”€ sql_transformations/     # Trino SQL scripts
â”‚   â””â”€â”€ unified_dataset/         # Python scripts for final dataset
â”œâ”€â”€ ml_pipelines/                # Machine learning pipelines
â”‚   â”œâ”€â”€ customer_segmentation/
â”‚   â”œâ”€â”€ forecasting/
â”‚   â”œâ”€â”€ journey_simulation/
â”‚   â””â”€â”€ campaign_optimization/
â”œâ”€â”€ api/                         # FastAPI application
â”œâ”€â”€ config/                      # Configuration files
â”‚   â””â”€â”€ database_config.yaml
â”œâ”€â”€ docs/                        # Documentation
â”œâ”€â”€ streamlit_app/               # Streamlit dashboard
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸš€ Quick Start

### 1. Prerequisites

- Python 3.8+
- MySQL 8.0+
- PostgreSQL 13+ (or install via Homebrew: `brew install postgresql`)
- MongoDB 5.0+
- Trino (for unified SQL queries)

### 2. Installation

```bash
# Clone the repository
git clone <repository-url>
cd amato_production

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Note: If you encounter PostgreSQL installation issues on macOS, run:
# brew install postgresql
# Then try installing requirements again
```

### 3. Database Setup

#### MySQL Setup
```bash
# Create database and user
mysql -u root -p
CREATE DATABASE amato_production;
CREATE USER 'amato_user'@'localhost' IDENTIFIED BY 'amato_password';
GRANT ALL PRIVILEGES ON amato_production.* TO 'amato_user'@'localhost';
FLUSH PRIVILEGES;
EXIT;

# Run DDL
mysql -u amato_user -p amato_production < ddl/mysql_schema.sql
```

#### PostgreSQL Setup
```bash
# Create database and user
sudo -u postgres psql
CREATE DATABASE amato_production;
CREATE USER amato_user WITH PASSWORD 'amato_password';
GRANT ALL PRIVILEGES ON DATABASE amato_production TO amato_user;
\q

# Run DDL
psql -U amato_user -d amato_production -f ddl/postgresql_schema.sql
```

#### MongoDB Setup
```bash
# Start MongoDB
mongod

# Run schema script
mongo < ddl/mongodb_schema.js
```

### 4. Data Generation

```bash
# Generate all data
python data_generation/generate_all_data.py
```

### 5. Run Data Pipelines

```bash
# Run SQL transformations (Trino)
# (Trino setup required)

# Run unified dataset creation
python data_pipelines/unified_dataset/create_unified_dataset.py
```

### 6. Run ML Pipelines

```bash
# Customer Segmentation
python ml_pipelines/customer_segmentation/train_segmentation_models.py

# Forecasting
python ml_pipelines/forecasting/train_forecasting_models.py

# Journey Simulation
python ml_pipelines/journey_simulation/train_journey_models.py

# Campaign Optimization
python ml_pipelines/campaign_optimization/train_optimization_models.py
```

### 7. Start API Server

```bash
# Start FastAPI server
uvicorn api.main:app --host 0.0.0.0 --port 8000 --reload
```

### 8. Start Streamlit Dashboard

```bash
# Start Streamlit app
streamlit run streamlit_app/app.py
```

## ğŸ“Š Data Flow

### 1. Data Sources
- **MySQL**: Customer profiles, transactions, demographics
- **PostgreSQL**: Marketing campaigns, A/B test results
- **MongoDB**: Clickstream data (sessions, page views, events)

### 2. Data Processing
- **Trino SQL**: Cross-database queries and transformations
- **Python**: Data cleaning, feature engineering, aggregation

### 3. ML Models
- **Customer Segmentation**: K-means, HDBSCAN clustering
- **Forecasting**: Prophet, XGBoost time series
- **Journey Simulation**: LightGBM, Random Forest
- **Campaign Optimization**: XGBoost, Random Forest

### 4. Outputs
- **Parquet Files**: Processed datasets
- **Pickle Files**: Trained models
- **API Endpoints**: Real-time inference
- **Dashboard**: Interactive exploration

## ğŸ”§ Configuration

Edit `config/database_config.yaml` to configure:
- Database connections
- Data generation parameters
- ML model settings
- API configuration

## ğŸ“ˆ Use Cases

### 1. Customer Segmentation
- **Input**: Customer RFM scores, behavioral patterns
- **Output**: Customer segments with characteristics
- **Business Value**: Targeted marketing, personalized experiences

### 2. Revenue Forecasting
- **Input**: Historical transaction data, campaign performance
- **Output**: Revenue predictions with confidence intervals
- **Business Value**: Budget planning, growth projections

### 3. Customer Journey Analysis
- **Input**: Clickstream data, conversion events
- **Output**: Journey patterns, conversion optimization
- **Business Value**: UX improvement, conversion rate optimization

### 4. Campaign Optimization
- **Input**: A/B test results, campaign performance
- **Output**: Optimal campaign strategies
- **Business Value**: Marketing efficiency, ROI improvement

## ğŸ§ª Testing

```bash
# Run tests
pytest tests/

# Run specific pipeline tests
python -m pytest tests/test_data_pipelines.py
python -m pytest tests/test_ml_pipelines.py
```

## ğŸ“ Logging

Logs are stored in `logs/` directory:
- `data_generation.log`: Data generation process
- `pipeline_execution.log`: Pipeline execution logs
- `api_access.log`: API access logs

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ†˜ Support

For support and questions:
- Create an issue in the repository
- Check the documentation in `docs/`
- Review the logs for error details

## ğŸ”„ Version History

- **v1.0.0**: Initial production release
  - Multi-database architecture
  - Complete data pipelines
  - ML model training and inference
  - Interactive dashboard
