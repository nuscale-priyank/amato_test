{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AMATO Production - Journey Simulation Batch Inference Pipeline\n",
        "\n",
        "This notebook performs batch inference for customer journey stage prediction and conversion probability.\n",
        "\n",
        "**Author:** Data Science Team  \n",
        "**Date:** 2024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîß Using project root: /Users/priyankmavani/Desktop/apps/amato\n",
            "‚úÖ Successfully imported utils.s3_utils\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yaml\n",
        "import logging\n",
        "import os\n",
        "import sys\n",
        "import joblib\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Add project root to path for imports\n",
        "# Try multiple possible paths for Jupyter notebook compatibility\n",
        "possible_paths = [\n",
        "    Path.cwd(),  # Current working directory\n",
        "    Path.cwd().parent,  # Parent of current directory\n",
        "    Path.cwd().parent.parent,  # Grandparent of current directory\n",
        "    Path(__file__).parent.parent.parent if '__file__' in globals() else None  # If __file__ exists\n",
        "]\n",
        "\n",
        "# Filter out None values and find the one with utils folder\n",
        "project_root = None\n",
        "for path in possible_paths:\n",
        "    if path and (path / 'utils').exists():\n",
        "        project_root = path\n",
        "        break\n",
        "\n",
        "if project_root is None:\n",
        "    # Fallback: use current directory and hope for the best\n",
        "    project_root = Path.cwd()\n",
        "\n",
        "sys.path.append(str(project_root))\n",
        "print(f\"üîß Using project root: {project_root}\")\n",
        "\n",
        "try:\n",
        "    from utils.s3_utils import get_s3_manager\n",
        "    print(\"‚úÖ Successfully imported utils.s3_utils\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Failed to import utils.s3_utils: {e}\")\n",
        "    print(\"üîß Trying alternative import...\")\n",
        "    try:\n",
        "        # Try relative import\n",
        "        sys.path.append('.')\n",
        "        from utils.s3_utils import get_s3_manager\n",
        "        print(\"‚úÖ Successfully imported with relative path\")\n",
        "    except ImportError as e2:\n",
        "        print(f\"‚ùå Alternative import also failed: {e2}\")\n",
        "        raise\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Journey Simulation Batch Inference Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "class JourneySimulationBatchInference:\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the Journey Simulation Batch Inference Pipeline\"\"\"\n",
        "        self.models = {}\n",
        "        self.scalers = {}\n",
        "        self.metadata = {}\n",
        "        \n",
        "    def load_trained_models(self):\n",
        "        \"\"\"Load trained journey simulation models from S3\"\"\"\n",
        "        logger.info(\"üì• Loading trained journey simulation models...\")\n",
        "        \n",
        "        try:\n",
        "            s3_manager = get_s3_manager()\n",
        "            \n",
        "            # Create models directory if it doesn't exist\n",
        "            models_dir = 'models/journey_simulation'\n",
        "            os.makedirs(models_dir, exist_ok=True)\n",
        "            \n",
        "            # Load Journey Stage model\n",
        "            journey_stage_model_path = f'{models_dir}/journey_stage_model.pkl'\n",
        "            journey_stage_scaler_path = f'{models_dir}/journey_stage_scaler.pkl'\n",
        "            \n",
        "            # Download Journey Stage model from S3 if not exists locally\n",
        "            if not os.path.exists(journey_stage_model_path):\n",
        "                logger.info(\"üì• Downloading Journey Stage model from S3...\")\n",
        "                try:\n",
        "                    s3_manager.download_file('amato_pm/models/journey_simulation/journey_stage_model.pkl', journey_stage_model_path)\n",
        "                    logger.info(\"‚úÖ Downloaded Journey Stage model from S3\")\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"‚ö†Ô∏è  Failed to download Journey Stage model from S3: {e}\")\n",
        "            \n",
        "            # Download Journey Stage scaler from S3 if not exists locally\n",
        "            if not os.path.exists(journey_stage_scaler_path):\n",
        "                logger.info(\"üì• Downloading Journey Stage scaler from S3...\")\n",
        "                try:\n",
        "                    s3_manager.download_file('amato_pm/models/journey_simulation/journey_stage_scaler.pkl', journey_stage_scaler_path)\n",
        "                    logger.info(\"‚úÖ Downloaded Journey Stage scaler from S3\")\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"‚ö†Ô∏è  Failed to download Journey Stage scaler from S3: {e}\")\n",
        "            \n",
        "            # Load Journey Stage model if available\n",
        "            if os.path.exists(journey_stage_model_path):\n",
        "                self.models['journey_stage'] = joblib.load(journey_stage_model_path)\n",
        "                if os.path.exists(journey_stage_scaler_path):\n",
        "                    self.scalers['journey_stage'] = joblib.load(journey_stage_scaler_path)\n",
        "                else:\n",
        "                    self.scalers['journey_stage'] = None\n",
        "                \n",
        "                # Create metadata with correct feature columns\n",
        "                self.metadata['journey_stage'] = {\n",
        "                    'feature_columns': [\n",
        "                        'recency_days', 'frequency', 'monetary_value',\n",
        "                        'avg_order_value', 'total_orders', 'days_since_first_order',\n",
        "                        'customer_lifetime_value', 'avg_days_between_orders',\n",
        "                        'order_count_30d', 'order_count_90d', 'order_count_365d',\n",
        "                        'revenue_30d', 'revenue_90d', 'revenue_365d'\n",
        "                    ],\n",
        "                    'model_type': 'RandomForestClassifier',\n",
        "                    'training_date': datetime.now().isoformat()\n",
        "                }\n",
        "                logger.info(\"‚úÖ Loaded Journey Stage model\")\n",
        "            else:\n",
        "                logger.warning(\"‚ö†Ô∏è  Journey Stage model not available\")\n",
        "            \n",
        "            # Load Conversion Prediction model\n",
        "            conversion_model_path = f'{models_dir}/conversion_prediction_model.pkl'\n",
        "            conversion_scaler_path = f'{models_dir}/conversion_prediction_scaler.pkl'\n",
        "            \n",
        "            # Download Conversion Prediction model from S3 if not exists locally\n",
        "            if not os.path.exists(conversion_model_path):\n",
        "                logger.info(\"üì• Downloading Conversion Prediction model from S3...\")\n",
        "                try:\n",
        "                    s3_manager.download_file('amato_pm/models/journey_simulation/conversion_prediction_model.pkl', conversion_model_path)\n",
        "                    logger.info(\"‚úÖ Downloaded Conversion Prediction model from S3\")\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"‚ö†Ô∏è  Failed to download Conversion Prediction model from S3: {e}\")\n",
        "            \n",
        "            # Download Conversion Prediction scaler from S3 if not exists locally\n",
        "            if not os.path.exists(conversion_scaler_path):\n",
        "                logger.info(\"üì• Downloading Conversion Prediction scaler from S3...\")\n",
        "                try:\n",
        "                    s3_manager.download_file('amato_pm/models/journey_simulation/conversion_prediction_scaler.pkl', conversion_scaler_path)\n",
        "                    logger.info(\"‚úÖ Downloaded Conversion Prediction scaler from S3\")\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"‚ö†Ô∏è  Failed to download Conversion Prediction scaler from S3: {e}\")\n",
        "            \n",
        "            # Load Conversion Prediction model if available\n",
        "            if os.path.exists(conversion_model_path):\n",
        "                self.models['conversion_prediction'] = joblib.load(conversion_model_path)\n",
        "                if os.path.exists(conversion_scaler_path):\n",
        "                    self.scalers['conversion_prediction'] = joblib.load(conversion_scaler_path)\n",
        "                else:\n",
        "                    self.scalers['conversion_prediction'] = None\n",
        "                \n",
        "                # Create metadata with correct feature columns\n",
        "                self.metadata['conversion_prediction'] = {\n",
        "                    'feature_columns': [\n",
        "                        'recency_days', 'frequency', 'monetary_value',\n",
        "                        'avg_order_value', 'total_orders', 'days_since_first_order',\n",
        "                        'customer_lifetime_value', 'avg_days_between_orders',\n",
        "                        'order_count_30d', 'order_count_90d', 'order_count_365d',\n",
        "                        'revenue_30d', 'revenue_90d', 'revenue_365d'\n",
        "                    ],\n",
        "                    'model_type': 'RandomForestClassifier',\n",
        "                    'training_date': datetime.now().isoformat()\n",
        "                }\n",
        "                logger.info(\"‚úÖ Loaded Conversion Prediction model\")\n",
        "            else:\n",
        "                logger.warning(\"‚ö†Ô∏è  Conversion Prediction model not available\")\n",
        "            \n",
        "            logger.info(f\"‚úÖ Loaded {len(self.models)} models\")\n",
        "            \n",
        "            if len(self.models) == 0:\n",
        "                logger.error(\"‚ùå No models loaded. Please ensure models are available in S3.\")\n",
        "                raise Exception(\"No models available for inference\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            logger.error(f\"‚ùå Failed to load models: {e}\")\n",
        "            raise\n",
        "    \n",
        "    def load_inference_data(self, data_path=None):\n",
        "        \"\"\"Load recent inference data for journey simulation\"\"\"\n",
        "        logger.info(\"üìä Loading recent inference data...\")\n",
        "        \n",
        "        try:\n",
        "            # Load recent inference data from S3\n",
        "            logger.info(\"üîç Loading recent inference data from S3...\")\n",
        "            s3_manager = get_s3_manager()\n",
        "            s3_manager.load_inference_data_from_s3()\n",
        "            logger.info(\"‚úÖ Recent inference data loaded from S3\")\n",
        "            \n",
        "            if data_path is None:\n",
        "                data_path = 'data_pipelines/unified_dataset/output/recent_customer_dataset.parquet'\n",
        "            \n",
        "            if os.path.exists(data_path):\n",
        "                df = pd.read_parquet(data_path)\n",
        "                logger.info(f\"‚úÖ Loaded recent inference data: {len(df)} customers\")\n",
        "                return df\n",
        "            else:\n",
        "                logger.error(f\"‚ùå Recent inference data not found at {data_path}\")\n",
        "                return None\n",
        "                \n",
        "        except Exception as e:\n",
        "            logger.error(f\"‚ùå Failed to load recent inference data: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def prepare_features(self, df, model_name):\n",
        "        \"\"\"Prepare features for inference\"\"\"\n",
        "        logger.info(f\"ÔøΩÔøΩ Preparing features for {model_name} inference...\")\n",
        "        \n",
        "        # Use EXACTLY the same features that were used during training\n",
        "        if model_name == 'journey_stage':\n",
        "            feature_columns = [\n",
        "                'recency_days', 'frequency', 'monetary_value',\n",
        "                'avg_order_value', 'total_orders', 'days_since_first_order',\n",
        "                'customer_lifetime_value', 'avg_days_between_orders',\n",
        "                'order_count_30d', 'order_count_90d', 'order_count_365d',\n",
        "                'revenue_30d', 'revenue_90d', 'revenue_365d'\n",
        "            ]\n",
        "        elif model_name == 'conversion_prediction':\n",
        "            feature_columns = [\n",
        "                'recency_days', 'frequency', 'monetary_value',\n",
        "                'avg_order_value', 'total_orders', 'days_since_first_order',\n",
        "                'customer_lifetime_value', 'avg_days_between_orders',\n",
        "                'order_count_30d', 'order_count_90d', 'order_count_365d',\n",
        "                'revenue_30d', 'revenue_90d', 'revenue_365d'\n",
        "            ]\n",
        "        else:\n",
        "            logger.error(f\"‚ùå Unknown model: {model_name}\")\n",
        "            return None\n",
        "        \n",
        "        # Filter available features\n",
        "        available_features = [col for col in feature_columns if col in df.columns]\n",
        "        \n",
        "        if len(available_features) < 5:\n",
        "            logger.warning(f\"‚ö†Ô∏è  Only {len(available_features)} features available for {model_name}\")\n",
        "            \n",
        "        # Create feature matrix with EXACTLY the same features used in training\n",
        "        X = df[available_features].copy()\n",
        "        \n",
        "        # Handle missing values\n",
        "        X = X.fillna(X.median())\n",
        "        \n",
        "        # Remove outliers using IQR method\n",
        "        for col in X.columns:\n",
        "            Q1 = X[col].quantile(0.25)\n",
        "            Q3 = X[col].quantile(0.75)\n",
        "            IQR = Q3 - Q1\n",
        "            lower_bound = Q1 - 1.5 * IQR\n",
        "            upper_bound = Q3 + 1.5 * IQR\n",
        "            X[col] = X[col].clip(lower_bound, upper_bound)\n",
        "        \n",
        "        logger.info(f\"‚úÖ Prepared {len(X)} customers with {len(X.columns)} features for {model_name}\")\n",
        "        return X\n",
        "    \n",
        "    def perform_journey_stage_prediction(self, df_features):\n",
        "        \"\"\"Perform journey stage prediction inference\"\"\"\n",
        "        logger.info(\"üéØ Performing journey stage prediction inference...\")\n",
        "        \n",
        "        if 'journey_stage' not in self.models:\n",
        "            logger.error(\"‚ùå Journey Stage model not loaded\")\n",
        "            return None\n",
        "        \n",
        "        # Scale features if scaler exists\n",
        "        if self.scalers['journey_stage'] is not None:\n",
        "            X_scaled = self.scalers['journey_stage'].transform(df_features)\n",
        "        else:\n",
        "            X_scaled = df_features\n",
        "        \n",
        "        # Predict journey stage\n",
        "        journey_stages = self.models['journey_stage'].predict(X_scaled)\n",
        "        \n",
        "        # Get stage probabilities if available\n",
        "        try:\n",
        "            stage_probs = self.models['journey_stage'].predict_proba(X_scaled)\n",
        "            max_probs = np.max(stage_probs, axis=1)\n",
        "        except:\n",
        "            max_probs = np.ones(len(journey_stages))\n",
        "        \n",
        "        # Create results dataframe\n",
        "        results = df_features.copy()\n",
        "        results['predicted_journey_stage'] = journey_stages\n",
        "        results['stage_confidence'] = max_probs\n",
        "        results['stage_category'] = pd.cut(max_probs, \n",
        "                                         bins=[0, 0.5, 0.8, 1.0], \n",
        "                                         labels=['Low', 'Medium', 'High'])\n",
        "        \n",
        "        logger.info(f\"‚úÖ Journey stage prediction completed: {len(results)} predictions\")\n",
        "        return results\n",
        "    \n",
        "    def perform_conversion_prediction(self, df_features):\n",
        "        \"\"\"Perform conversion prediction inference\"\"\"\n",
        "        logger.info(\"üéØ Performing conversion prediction inference...\")\n",
        "        \n",
        "        if 'conversion_prediction' not in self.models:\n",
        "            logger.error(\"‚ùå Conversion Prediction model not loaded\")\n",
        "            return None\n",
        "        \n",
        "        # Scale features if scaler exists\n",
        "        if self.scalers['conversion_prediction'] is not None:\n",
        "            X_scaled = self.scalers['conversion_prediction'].transform(df_features)\n",
        "        else:\n",
        "            X_scaled = df_features\n",
        "        \n",
        "        # Predict conversion probability\n",
        "        conversion_probs = self.models['conversion_prediction'].predict_proba(X_scaled)[:, 1]\n",
        "        \n",
        "        # Create results dataframe\n",
        "        results = df_features.copy()\n",
        "        results['conversion_probability'] = conversion_probs\n",
        "        results['conversion_prediction'] = (conversion_probs > 0.5).astype(int)\n",
        "        results['conversion_category'] = pd.cut(conversion_probs, \n",
        "                                             bins=[0, 0.3, 0.7, 1.0], \n",
        "                                             labels=['Low', 'Medium', 'High'])\n",
        "        \n",
        "        logger.info(f\"‚úÖ Conversion prediction completed: {len(results)} predictions\")\n",
        "        return results\n",
        "    \n",
        "    def save_inference_results(self, results, model_name):\n",
        "        \"\"\"Save inference results directly to S3\"\"\"\n",
        "        logger.info(f\"üíæ Saving {model_name} inference results...\")\n",
        "        \n",
        "        try:\n",
        "            s3_manager = get_s3_manager()\n",
        "            \n",
        "            # Save results directly to S3\n",
        "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "            results_key = f'models/journey_simulation/inference_results/{model_name}_inference_results_{timestamp}.parquet'\n",
        "            \n",
        "            # Convert to parquet bytes and upload\n",
        "            results_bytes = results.to_parquet(index=False)\n",
        "            results_success = s3_manager.upload_bytes_direct(\n",
        "                results_bytes, results_key, 'application/octet-stream'\n",
        "            )\n",
        "            \n",
        "            # Generate and save report\n",
        "            report = self.generate_inference_report(results, model_name)\n",
        "            report_key = f'models/journey_simulation/inference_results/{model_name}_inference_report_{timestamp}.yaml'\n",
        "            \n",
        "            report_success = s3_manager.upload_bytes_direct(\n",
        "                yaml.dump(report, default_flow_style=False).encode('utf-8'),\n",
        "                report_key, 'text/yaml'\n",
        "            )\n",
        "            \n",
        "            if results_success and report_success:\n",
        "                logger.info(f\"‚úÖ {model_name} results uploaded directly to S3\")\n",
        "                return results_key, report_key\n",
        "            else:\n",
        "                logger.warning(f\"‚ö†Ô∏è  Some {model_name} results failed to upload to S3\")\n",
        "                return None, None\n",
        "                \n",
        "        except Exception as e:\n",
        "            logger.error(f\"‚ùå Failed to save {model_name} results: {e}\")\n",
        "            return None, None\n",
        "    \n",
        "    def generate_inference_report(self, results, model_name):\n",
        "        \"\"\"Generate inference report\"\"\"\n",
        "        logger.info(f\"üìã Generating {model_name} inference report...\")\n",
        "        \n",
        "        if model_name == 'journey_stage':\n",
        "            report = {\n",
        "                'model_name': model_name,\n",
        "                'inference_date': datetime.now().isoformat(),\n",
        "                'total_customers': len(results),\n",
        "                'journey_stage_distribution': results['predicted_journey_stage'].value_counts().to_dict(),\n",
        "                'stage_confidence_stats': {\n",
        "                    'mean': float(results['stage_confidence'].mean()),\n",
        "                    'median': float(results['stage_confidence'].median()),\n",
        "                    'std': float(results['stage_confidence'].std())\n",
        "                },\n",
        "                'stage_category_distribution': results['stage_category'].value_counts().to_dict(),\n",
        "                'feature_summary': {\n",
        "                    'total_features': len(results.columns),\n",
        "                    'numeric_features': len(results.select_dtypes(include=[np.number]).columns),\n",
        "                    'categorical_features': len(results.select_dtypes(include=['object']).columns)\n",
        "                }\n",
        "            }\n",
        "        elif model_name == 'conversion_prediction':\n",
        "            report = {\n",
        "                'model_name': model_name,\n",
        "                'inference_date': datetime.now().isoformat(),\n",
        "                'total_customers': len(results),\n",
        "                'conversion_probability_stats': {\n",
        "                    'mean': float(results['conversion_probability'].mean()),\n",
        "                    'median': float(results['conversion_probability'].median()),\n",
        "                    'std': float(results['conversion_probability'].std())\n",
        "                },\n",
        "                'conversion_prediction_distribution': results['conversion_prediction'].value_counts().to_dict(),\n",
        "                'conversion_category_distribution': results['conversion_category'].value_counts().to_dict(),\n",
        "                'feature_summary': {\n",
        "                    'total_features': len(results.columns),\n",
        "                    'numeric_features': len(results.select_dtypes(include=[np.number]).columns),\n",
        "                    'categorical_features': len(results.select_dtypes(include=['object']).columns)\n",
        "                }\n",
        "            }\n",
        "        else:\n",
        "            report = {\n",
        "                'model_name': model_name,\n",
        "                'inference_date': datetime.now().isoformat(),\n",
        "                'total_customers': len(results),\n",
        "                'feature_summary': {\n",
        "                    'total_features': len(results.columns),\n",
        "                    'numeric_features': len(results.select_dtypes(include=[np.number]).columns),\n",
        "                    'categorical_features': len(results.select_dtypes(include=['object']).columns)\n",
        "                }\n",
        "            }\n",
        "        \n",
        "        return report\n",
        "    \n",
        "    def create_inference_visualizations(self, results, model_name):\n",
        "        \"\"\"Create inference visualizations and upload directly to S3\"\"\"\n",
        "        logger.info(f\"üìä Creating {model_name} inference visualizations...\")\n",
        "        \n",
        "        try:\n",
        "            s3_manager = get_s3_manager()\n",
        "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "            \n",
        "            if model_name == 'journey_stage':\n",
        "                # Journey stage distribution\n",
        "                fig1 = px.bar(\n",
        "                    x=results['predicted_journey_stage'].value_counts().index,\n",
        "                    y=results['predicted_journey_stage'].value_counts().values,\n",
        "                    title=f'{model_name.replace(\"_\", \" \").title()} Distribution',\n",
        "                    labels={'x': 'Journey Stage', 'y': 'Customer Count'}\n",
        "                )\n",
        "                \n",
        "                # Stage confidence distribution\n",
        "                fig2 = px.histogram(\n",
        "                    results, x='stage_confidence',\n",
        "                    title=f'{model_name.replace(\"_\", \" \").title()} Confidence Distribution',\n",
        "                    labels={'stage_confidence': 'Stage Confidence', 'count': 'Customer Count'}\n",
        "                )\n",
        "                \n",
        "                # Upload visualizations directly to S3\n",
        "                html1_key = f'models/journey_simulation/inference_results/{model_name}_stage_distribution_{timestamp}.html'\n",
        "                html2_key = f'models/journey_simulation/inference_results/{model_name}_confidence_distribution_{timestamp}.html'\n",
        "                \n",
        "            elif model_name == 'conversion_prediction':\n",
        "                # Conversion probability distribution\n",
        "                fig1 = px.histogram(\n",
        "                    results, x='conversion_probability',\n",
        "                    title=f'{model_name.replace(\"_\", \" \").title()} Probability Distribution',\n",
        "                    labels={'conversion_probability': 'Conversion Probability', 'count': 'Customer Count'}\n",
        "                )\n",
        "                \n",
        "                # Conversion category distribution\n",
        "                fig2 = px.pie(\n",
        "                    values=results['conversion_category'].value_counts().values,\n",
        "                    names=results['conversion_category'].value_counts().index,\n",
        "                    title=f'{model_name.replace(\"_\", \" \").title()} Category Distribution'\n",
        "                )\n",
        "                \n",
        "                # Upload visualizations directly to S3\n",
        "                html1_key = f'models/journey_simulation/inference_results/{model_name}_probability_distribution_{timestamp}.html'\n",
        "                html2_key = f'models/journey_simulation/inference_results/{model_name}_category_distribution_{timestamp}.html'\n",
        "            \n",
        "            # Convert figures to HTML and upload\n",
        "            html1_bytes = fig1.to_html().encode('utf-8')\n",
        "            html2_bytes = fig2.to_html().encode('utf-8')\n",
        "            \n",
        "            s3_manager.upload_bytes_direct(html1_bytes, html1_key, 'text/html')\n",
        "            s3_manager.upload_bytes_direct(html2_bytes, html2_key, 'text/html')\n",
        "            \n",
        "            logger.info(f\"‚úÖ {model_name} visualizations uploaded directly to S3\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            logger.error(f\"‚ùå Failed to create {model_name} visualizations: {e}\")\n",
        "    \n",
        "    def run_batch_inference(self, data_path=None, models=None):\n",
        "        \"\"\"Run batch inference for all models\"\"\"\n",
        "        logger.info(\"üöÄ Starting Journey Simulation Batch Inference...\")\n",
        "        \n",
        "        try:\n",
        "            # Load models\n",
        "            self.load_trained_models()\n",
        "            \n",
        "            # Load data\n",
        "            df = self.load_inference_data(data_path)\n",
        "            if df is None:\n",
        "                raise Exception(\"Failed to load inference data\")\n",
        "            \n",
        "            # Determine which models to run\n",
        "            if models is None:\n",
        "                models = list(self.models.keys())\n",
        "            \n",
        "            all_results = {}\n",
        "            \n",
        "            for model_name in models:\n",
        "                if model_name not in self.models:\n",
        "                    logger.warning(f\"‚ö†Ô∏è Model {model_name} not found, skipping...\")\n",
        "                    continue\n",
        "                \n",
        "                # Prepare features\n",
        "                df_features = self.prepare_features(df, model_name)\n",
        "                \n",
        "                if df_features is None or len(df_features) == 0:\n",
        "                    logger.warning(f\"‚ö†Ô∏è  No features prepared for {model_name}, skipping...\")\n",
        "                    continue\n",
        "                \n",
        "                # Perform inference\n",
        "                if model_name == 'journey_stage':\n",
        "                    results = self.perform_journey_stage_prediction(df_features)\n",
        "                elif model_name == 'conversion_prediction':\n",
        "                    results = self.perform_conversion_prediction(df_features)\n",
        "                else:\n",
        "                    logger.warning(f\"‚ö†Ô∏è  Unknown model: {model_name}\")\n",
        "                    continue\n",
        "                \n",
        "                if results is not None:\n",
        "                    # Save results\n",
        "                    results_file, report_file = self.save_inference_results(results, model_name)\n",
        "                    \n",
        "                    # Create visualizations\n",
        "                    self.create_inference_visualizations(results, model_name)\n",
        "                    \n",
        "                    all_results[model_name] = results\n",
        "                    \n",
        "                    logger.info(f\"‚úÖ {model_name} batch inference completed\")\n",
        "            \n",
        "            logger.info(\"=\" * 60)\n",
        "            logger.info(\"üéâ BATCH INFERENCE COMPLETED!\")\n",
        "            logger.info(\"=\" * 60)\n",
        "            logger.info(f\"üìä Processed {len(df)} customers\")\n",
        "            logger.info(f\"üéØ Ran inference for {len(all_results)} models\")\n",
        "            \n",
        "            return all_results\n",
        "            \n",
        "        except Exception as e:\n",
        "            logger.error(f\"‚ùå Error in batch inference: {e}\")\n",
        "            raise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run the Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:üöÄ Starting Journey Simulation Batch Inference...\n",
            "INFO:__main__:üì• Loading trained journey simulation models...\n",
            "INFO:__main__:‚úÖ Loaded Journey Stage model\n",
            "INFO:__main__:‚úÖ Loaded Conversion Prediction model\n",
            "INFO:__main__:‚úÖ Loaded 2 models\n",
            "INFO:__main__:üìä Loading recent inference data...\n",
            "INFO:__main__:üîç Loading recent inference data from S3...\n",
            "INFO:utils.s3_utils:Loading recent inference data from S3 (last 3 months)...\n",
            "INFO:utils.s3_utils:Loading data newer than 2025-06-03\n",
            "INFO:utils.s3_utils:Downloading s3://nuscale-data-services-public/amato_pm/data_pipelines/unified_dataset/output//unified_customer_dataset.parquet to data_pipelines/unified_dataset/output/unified_customer_dataset.parquet\n",
            "INFO:utils.s3_utils:Downloading s3://nuscale-data-services-public/amato_pm/data_pipelines/unified_dataset/output//unified_dataset_report.yaml to data_pipelines/unified_dataset/output/unified_dataset_report.yaml\n",
            "INFO:utils.s3_utils:Downloading s3://nuscale-data-services-public/amato_pm/data_pipelines/unified_dataset/output//unified_dataset_summary.yaml to data_pipelines/unified_dataset/output/unified_dataset_summary.yaml\n",
            "INFO:utils.s3_utils:Downloading s3://nuscale-data-services-public/amato_pm/data_pipelines/unified_dataset/output/recent_customer_dataset.parquet to data_pipelines/unified_dataset/output/recent_customer_dataset.parquet\n",
            "INFO:utils.s3_utils:Downloading s3://nuscale-data-services-public/amato_pm/data_pipelines/unified_dataset/output/timeline_datasets_metadata.yaml to data_pipelines/unified_dataset/output/timeline_datasets_metadata.yaml\n",
            "INFO:utils.s3_utils:Downloading s3://nuscale-data-services-public/amato_pm/data_pipelines/unified_dataset/output/unified_customer_dataset.parquet to data_pipelines/unified_dataset/output/unified_customer_dataset.parquet\n",
            "INFO:utils.s3_utils:Downloading s3://nuscale-data-services-public/amato_pm/data_pipelines/unified_dataset/output/unified_dataset_report.yaml to data_pipelines/unified_dataset/output/unified_dataset_report.yaml\n",
            "INFO:utils.s3_utils:Downloading s3://nuscale-data-services-public/amato_pm/data_pipelines/unified_dataset/output/unified_dataset_summary.yaml to data_pipelines/unified_dataset/output/unified_dataset_summary.yaml\n",
            "INFO:__main__:‚úÖ Recent inference data loaded from S3\n",
            "INFO:__main__:‚úÖ Loaded recent inference data: 1196 customers\n",
            "INFO:__main__:ÔøΩÔøΩ Preparing features for journey_stage inference...\n",
            "INFO:__main__:‚úÖ Prepared 1196 customers with 5 features for journey_stage\n",
            "INFO:__main__:üéØ Performing journey stage prediction inference...\n",
            "INFO:__main__:‚úÖ Journey stage prediction completed: 1196 predictions\n",
            "INFO:__main__:üíæ Saving journey_stage inference results...\n",
            "INFO:utils.s3_utils:Uploading bytes directly to s3://nuscale-data-services-public/models/journey_simulation/inference_results/journey_stage_inference_results_20250901_232758.parquet\n",
            "INFO:utils.s3_utils:Successfully uploaded bytes to s3://nuscale-data-services-public/models/journey_simulation/inference_results/journey_stage_inference_results_20250901_232758.parquet\n",
            "INFO:__main__:üìã Generating journey_stage inference report...\n",
            "INFO:utils.s3_utils:Uploading bytes directly to s3://nuscale-data-services-public/models/journey_simulation/inference_results/journey_stage_inference_report_20250901_232758.yaml\n",
            "INFO:utils.s3_utils:Successfully uploaded bytes to s3://nuscale-data-services-public/models/journey_simulation/inference_results/journey_stage_inference_report_20250901_232758.yaml\n",
            "INFO:__main__:‚úÖ journey_stage results uploaded directly to S3\n",
            "INFO:__main__:üìä Creating journey_stage inference visualizations...\n",
            "INFO:utils.s3_utils:Uploading bytes directly to s3://nuscale-data-services-public/models/journey_simulation/inference_results/journey_stage_stage_distribution_20250901_232758.html\n",
            "INFO:utils.s3_utils:Successfully uploaded bytes to s3://nuscale-data-services-public/models/journey_simulation/inference_results/journey_stage_stage_distribution_20250901_232758.html\n",
            "INFO:utils.s3_utils:Uploading bytes directly to s3://nuscale-data-services-public/models/journey_simulation/inference_results/journey_stage_confidence_distribution_20250901_232758.html\n",
            "INFO:utils.s3_utils:Successfully uploaded bytes to s3://nuscale-data-services-public/models/journey_simulation/inference_results/journey_stage_confidence_distribution_20250901_232758.html\n",
            "INFO:__main__:‚úÖ journey_stage visualizations uploaded directly to S3\n",
            "INFO:__main__:‚úÖ journey_stage batch inference completed\n",
            "INFO:__main__:ÔøΩÔøΩ Preparing features for conversion_prediction inference...\n",
            "INFO:__main__:‚úÖ Prepared 1196 customers with 5 features for conversion_prediction\n",
            "INFO:__main__:üéØ Performing conversion prediction inference...\n",
            "INFO:__main__:‚úÖ Conversion prediction completed: 1196 predictions\n",
            "INFO:__main__:üíæ Saving conversion_prediction inference results...\n",
            "INFO:utils.s3_utils:Uploading bytes directly to s3://nuscale-data-services-public/models/journey_simulation/inference_results/conversion_prediction_inference_results_20250901_232803.parquet\n",
            "INFO:utils.s3_utils:Successfully uploaded bytes to s3://nuscale-data-services-public/models/journey_simulation/inference_results/conversion_prediction_inference_results_20250901_232803.parquet\n",
            "INFO:__main__:üìã Generating conversion_prediction inference report...\n",
            "INFO:utils.s3_utils:Uploading bytes directly to s3://nuscale-data-services-public/models/journey_simulation/inference_results/conversion_prediction_inference_report_20250901_232803.yaml\n",
            "INFO:utils.s3_utils:Successfully uploaded bytes to s3://nuscale-data-services-public/models/journey_simulation/inference_results/conversion_prediction_inference_report_20250901_232803.yaml\n",
            "INFO:__main__:‚úÖ conversion_prediction results uploaded directly to S3\n",
            "INFO:__main__:üìä Creating conversion_prediction inference visualizations...\n",
            "INFO:utils.s3_utils:Uploading bytes directly to s3://nuscale-data-services-public/models/journey_simulation/inference_results/conversion_prediction_probability_distribution_20250901_232804.html\n",
            "INFO:utils.s3_utils:Successfully uploaded bytes to s3://nuscale-data-services-public/models/journey_simulation/inference_results/conversion_prediction_probability_distribution_20250901_232804.html\n",
            "INFO:utils.s3_utils:Uploading bytes directly to s3://nuscale-data-services-public/models/journey_simulation/inference_results/conversion_prediction_category_distribution_20250901_232804.html\n",
            "INFO:utils.s3_utils:Successfully uploaded bytes to s3://nuscale-data-services-public/models/journey_simulation/inference_results/conversion_prediction_category_distribution_20250901_232804.html\n",
            "INFO:__main__:‚úÖ conversion_prediction visualizations uploaded directly to S3\n",
            "INFO:__main__:‚úÖ conversion_prediction batch inference completed\n",
            "INFO:__main__:============================================================\n",
            "INFO:__main__:üéâ BATCH INFERENCE COMPLETED!\n",
            "INFO:__main__:============================================================\n",
            "INFO:__main__:üìä Processed 1196 customers\n",
            "INFO:__main__:üéØ Ran inference for 2 models\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üéâ Journey Simulation Batch Inference completed successfully!\n",
            "üìä Results saved to models/journey_simulation/inference_results/\n",
            "üöÄ Ready for customer journey analysis and conversion optimization!\n"
          ]
        }
      ],
      "source": [
        "# Initialize and run the pipeline\n",
        "if __name__ == \"__main__\":\n",
        "    inference = JourneySimulationBatchInference()\n",
        "    results = inference.run_batch_inference()\n",
        "    \n",
        "    print(\"\\nüéâ Journey Simulation Batch Inference completed successfully!\")\n",
        "    print(f\"üìä Results saved to models/journey_simulation/inference_results/\")\n",
        "    print(\"üöÄ Ready for customer journey analysis and conversion optimization!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
