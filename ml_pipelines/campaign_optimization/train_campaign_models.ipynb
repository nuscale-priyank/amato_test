{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "440579c4",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yaml\n",
        "import logging\n",
        "import os\n",
        "import sys\n",
        "import joblib\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "\n",
        "possible_paths = [\n",
        "    Path.cwd(),  # Current working directory\n",
        "    Path.cwd().parent,  # Parent of current directory\n",
        "    Path.cwd().parent.parent,  # Grandparent of current directory\n",
        "    Path(__file__).parent.parent.parent if '__file__' in globals() else None  # If __file__ exists\n",
        "]\n",
        "\n",
        "# Filter out None values and find the one with utils folder\n",
        "project_root = None\n",
        "for path in possible_paths:\n",
        "    if path and (path / 'utils').exists():\n",
        "        project_root = path\n",
        "        break\n",
        "# Add project root to path for imports\n",
        "sys.path.append(str(project_root))\n",
        "\n",
        "from utils.s3_utils import get_s3_manager\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class CampaignOptimizationPipeline:\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the Campaign Optimization Pipeline\"\"\"\n",
        "        self.models = {}\n",
        "        self.scalers = {}\n",
        "        self.metadata = {}\n",
        "        \n",
        "    def load_data(self):\n",
        "        \"\"\"Load historical training data for campaign optimization (before 3 months ago)\"\"\"\n",
        "        try:\n",
        "            # Load historical training data from S3\n",
        "            logger.info(\"üîç Loading historical training data from S3...\")\n",
        "            s3_manager = get_s3_manager()\n",
        "            s3_manager.load_training_data_from_s3()\n",
        "            logger.info(\"‚úÖ Historical training data loaded from S3\")\n",
        "            \n",
        "            # Load the training dataset (historical data)\n",
        "            data_path = 'data_pipelines/unified_dataset/output/unified_customer_dataset.parquet'\n",
        "            \n",
        "            if os.path.exists(data_path):\n",
        "                df = pd.read_parquet(data_path)\n",
        "                logger.info(f\"‚úÖ Loaded historical training dataset: {df.shape}\")\n",
        "                logger.info(f\"üìÖ This dataset contains historical data for model training\")\n",
        "                return df\n",
        "            else:\n",
        "                logger.error(f\"‚ùå Historical training dataset not found at {data_path}\")\n",
        "                return None\n",
        "        except Exception as e:\n",
        "            logger.error(f\"‚ùå Failed to load historical training data: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def prepare_features(self, df, target_col):\n",
        "        \"\"\"Prepare features for campaign optimization\"\"\"\n",
        "        logger.info(f\"üîß Preparing features for {target_col}...\")\n",
        "        \n",
        "        # Select features based on target - use columns that actually exist\n",
        "        if target_col == 'campaign_success':\n",
        "            feature_columns = [\n",
        "                'recency_days', 'frequency', 'monetary_value',\n",
        "                'avg_order_value', 'customer_lifetime_value',\n",
        "                'campaign_count', 'avg_roas', 'avg_ctr', 'total_campaign_revenue',\n",
        "                'campaign_response_rate', 'avg_ctr_lift', 'rfm_score',\n",
        "                'total_sessions', 'total_events',\n",
        "                'conversion_probability', 'churn_risk', 'upsell_potential'\n",
        "            ]\n",
        "        elif target_col == 'budget_optimization':\n",
        "            feature_columns = [\n",
        "                'recency_days', 'frequency', 'monetary_value',\n",
        "                'avg_order_value', 'customer_lifetime_value',\n",
        "                'campaign_count', 'avg_roas', 'total_campaign_revenue',\n",
        "                'rfm_score', 'conversion_probability'\n",
        "            ]\n",
        "        else:\n",
        "            logger.error(f\"‚ùå Unknown target column: {target_col}\")\n",
        "            return None, None\n",
        "        \n",
        "        # Filter available features\n",
        "        available_features = [col for col in feature_columns if col in df.columns]\n",
        "        \n",
        "        if len(available_features) < 5:\n",
        "            logger.warning(f\"‚ö†Ô∏è  Only {len(available_features)} features available for {target_col}\")\n",
        "            \n",
        "        # Create feature matrix\n",
        "        X = df[available_features].copy()\n",
        "        \n",
        "        # Handle missing values\n",
        "        X = X.fillna(X.median())\n",
        "        \n",
        "        # Remove outliers using IQR method\n",
        "        for col in X.columns:\n",
        "            Q1 = X[col].quantile(0.25)\n",
        "            Q3 = X[col].quantile(0.75)\n",
        "            IQR = Q3 - Q1\n",
        "            lower_bound = Q1 - 1.5 * IQR\n",
        "            upper_bound = Q3 + 1.5 * IQR\n",
        "            X[col] = X[col].clip(lower_bound, upper_bound)\n",
        "        \n",
        "        # Create synthetic target variable if it doesn't exist\n",
        "        if target_col == 'campaign_success':\n",
        "            if 'campaign_success' not in df.columns:\n",
        "                # Create synthetic success based on campaign performance\n",
        "                y = ((df['avg_roas'] > df['avg_roas'].median()) & \n",
        "                     (df['avg_ctr'] > df['avg_ctr'].median())).astype(int)\n",
        "                logger.info(\"üîß Created synthetic campaign_success target\")\n",
        "            else:\n",
        "                y = df['campaign_success']\n",
        "        elif target_col == 'budget_optimization':\n",
        "            if 'optimal_budget' not in df.columns:\n",
        "                # Create synthetic optimal budget based on customer value\n",
        "                y = df['customer_lifetime_value'] * 0.1  # 10% of CLV\n",
        "                logger.info(\"üîß Created synthetic optimal_budget target\")\n",
        "            else:\n",
        "                y = df['optimal_budget']\n",
        "        \n",
        "        logger.info(f\"‚úÖ Prepared {len(X)} customers with {len(available_features)} features for {target_col}\")\n",
        "        return X, y\n",
        "    \n",
        "    def train_campaign_success_model(self, X, y):\n",
        "        \"\"\"Train campaign success prediction model\"\"\"\n",
        "        logger.info(\"üéØ Training Campaign Success model...\")\n",
        "        \n",
        "        try:\n",
        "            # Split data\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "            \n",
        "            # Scale features\n",
        "            scaler = StandardScaler()\n",
        "            X_train_scaled = scaler.fit_transform(X_train)\n",
        "            X_test_scaled = scaler.transform(X_test)\n",
        "            \n",
        "            # Train model\n",
        "            model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "            model.fit(X_train_scaled, y_train)\n",
        "            \n",
        "            # Evaluate\n",
        "            y_pred = model.predict(X_test_scaled)\n",
        "            accuracy = accuracy_score(y_test, y_pred)\n",
        "            f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "            \n",
        "            # Cross-validation\n",
        "            cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5)\n",
        "            \n",
        "            logger.info(f\"‚úÖ Campaign Success model trained successfully\")\n",
        "            logger.info(f\"   Accuracy: {accuracy:.4f}\")\n",
        "            logger.info(f\"   F1 Score: {f1:.4f}\")\n",
        "            logger.info(f\"   CV Score: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
        "            \n",
        "            # Store model and scaler\n",
        "            self.models['campaign_success'] = model\n",
        "            self.scalers['campaign_success'] = scaler\n",
        "            \n",
        "            # Store metadata\n",
        "            self.metadata['campaign_success'] = {\n",
        "                'feature_columns': list(X.columns),\n",
        "                'model_type': 'RandomForestClassifier',\n",
        "                'training_date': datetime.now().isoformat(),\n",
        "                'accuracy': accuracy,\n",
        "                'f1_score': f1,\n",
        "                'cv_score_mean': cv_scores.mean(),\n",
        "                'cv_score_std': cv_scores.std()\n",
        "            }\n",
        "            \n",
        "            return model, scaler, accuracy, f1\n",
        "            \n",
        "        except Exception as e:\n",
        "            logger.error(f\"‚ùå Failed to train Campaign Success model: {e}\")\n",
        "            return None, None, 0, 0\n",
        "    \n",
        "    def train_budget_optimization_model(self, X, y):\n",
        "        \"\"\"Train budget optimization model\"\"\"\n",
        "        logger.info(\"üéØ Training Budget Optimization model...\")\n",
        "        \n",
        "        try:\n",
        "            # Split data\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "            \n",
        "            # Scale features\n",
        "            scaler = StandardScaler()\n",
        "            X_train_scaled = scaler.fit_transform(X_train)\n",
        "            X_test_scaled = scaler.transform(X_test)\n",
        "            \n",
        "            # Train model\n",
        "            model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "            model.fit(X_train_scaled, y_train)\n",
        "            \n",
        "            # Evaluate\n",
        "            y_pred = model.predict(X_test_scaled)\n",
        "            mse = mean_squared_error(y_test, y_pred)\n",
        "            mae = mean_absolute_error(y_test, y_pred)\n",
        "            r2 = r2_score(y_test, y_pred)\n",
        "            \n",
        "            # Cross-validation\n",
        "            cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='r2')\n",
        "            \n",
        "            logger.info(f\"‚úÖ Budget Optimization model trained successfully\")\n",
        "            logger.info(f\"   MSE: {mse:.4f}\")\n",
        "            logger.info(f\"   MAE: {mae:.4f}\")\n",
        "            logger.info(f\"   R¬≤: {r2:.4f}\")\n",
        "            logger.info(f\"   CV R¬≤: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
        "            \n",
        "            # Store model and scaler\n",
        "            self.models['budget_optimization'] = model\n",
        "            self.scalers['budget_optimization'] = scaler\n",
        "            \n",
        "            # Store metadata\n",
        "            self.metadata['budget_optimization'] = {\n",
        "                'feature_columns': list(X.columns),\n",
        "                'model_type': 'RandomForestRegressor',\n",
        "                'training_date': datetime.now().isoformat(),\n",
        "                'mse': mse,\n",
        "                'mae': mae,\n",
        "                'r2_score': r2,\n",
        "                'cv_r2_mean': cv_scores.mean(),\n",
        "                'cv_r2_std': cv_scores.std()\n",
        "            }\n",
        "            \n",
        "            return model, scaler, mse, r2\n",
        "            \n",
        "        except Exception as e:\n",
        "            logger.error(f\"‚ùå Failed to train Budget Optimization model: {e}\")\n",
        "            return None, None, 0, 0\n",
        "    \n",
        "    def save_models_direct(self):\n",
        "        \"\"\"Save models directly to S3\"\"\"\n",
        "        logger.info(\"üíæ Saving models directly to S3...\")\n",
        "        \n",
        "        try:\n",
        "            s3_manager = get_s3_manager()\n",
        "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "            \n",
        "            for model_name, model in self.models.items():\n",
        "                # Save model\n",
        "                model_key = f'models/campaign_optimization/{model_name}_model.pkl'\n",
        "                model_bytes = joblib.dumps(model)\n",
        "                model_success = s3_manager.upload_bytes_direct(\n",
        "                    model_bytes, model_key, 'application/octet-stream'\n",
        "                )\n",
        "                \n",
        "                # Save scaler if exists\n",
        "                if model_name in self.scalers and self.scalers[model_name] is not None:\n",
        "                    scaler_key = f'models/campaign_optimization/{model_name}_scaler.pkl'\n",
        "                    scaler_bytes = joblib.dumps(self.scalers[model_name])\n",
        "                    scaler_success = s3_manager.upload_bytes_direct(\n",
        "                        scaler_bytes, scaler_key, 'application/octet-stream'\n",
        "                    )\n",
        "                else:\n",
        "                    scaler_success = True\n",
        "                \n",
        "                # Save metadata\n",
        "                metadata_key = f'models/campaign_optimization/{model_name}_metadata.yaml'\n",
        "                metadata_bytes = yaml.dump(self.metadata[model_name], default_flow_style=False).encode('utf-8')\n",
        "                metadata_success = s3_manager.upload_bytes_direct(\n",
        "                    metadata_bytes, metadata_key, 'text/yaml'\n",
        "                )\n",
        "                \n",
        "                if model_success and scaler_success and metadata_success:\n",
        "                    logger.info(f\"‚úÖ {model_name} model, scaler, and metadata uploaded to S3\")\n",
        "                else:\n",
        "                    logger.warning(f\"‚ö†Ô∏è  Some {model_name} files failed to upload to S3\")\n",
        "            \n",
        "            logger.info(\"‚úÖ All models saved directly to S3\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            logger.error(f\"‚ùå Failed to save models: {e}\")\n",
        "    \n",
        "    def run_training_pipeline(self):\n",
        "        \"\"\"Run the complete training pipeline\"\"\"\n",
        "        logger.info(\"üöÄ Starting Campaign Optimization Training Pipeline...\")\n",
        "        \n",
        "        try:\n",
        "            # Load data\n",
        "            df = self.load_data()\n",
        "            if df is None:\n",
        "                raise Exception(\"Failed to load training data\")\n",
        "            \n",
        "            # Train Campaign Success model\n",
        "            X_success, y_success = self.prepare_features(df, 'campaign_success')\n",
        "            if X_success is not None and y_success is not None:\n",
        "                self.train_campaign_success_model(X_success, y_success)\n",
        "            \n",
        "            # Train Budget Optimization model\n",
        "            X_budget, y_budget = self.prepare_features(df, 'budget_optimization')\n",
        "            if X_budget is not None and y_budget is not None:\n",
        "                self.train_budget_optimization_model(X_budget, y_budget)\n",
        "            \n",
        "            # Save models\n",
        "            if self.models:\n",
        "                self.save_models_direct()\n",
        "                \n",
        "                logger.info(\"=\" * 60)\n",
        "                logger.info(\"üéâ TRAINING COMPLETED!\")\n",
        "                logger.info(\"=\" * 60)\n",
        "                logger.info(f\"üìä Trained {len(self.models)} models on {len(df)} customers\")\n",
        "                logger.info(f\"üîß Used features: {list(self.models.keys())}\")\n",
        "                logger.info(f\"üíæ Models saved to: S3\")\n",
        "                \n",
        "                return True\n",
        "            else:\n",
        "                logger.error(\"‚ùå No models were trained successfully\")\n",
        "                return False\n",
        "                \n",
        "        except Exception as e:\n",
        "            logger.error(f\"‚ùå Error in training pipeline: {e}\")\n",
        "            return False"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5bf0ce4",
      "metadata": {},
      "source": [
        "## Run the Training Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b769a648",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:üöÄ Starting Campaign Optimization Training Pipeline...\n",
            "INFO:__main__:üîç Loading historical training data from S3...\n",
            "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
            "INFO:utils.s3_utils:Loading historical training data from S3 with smart caching...\n",
            "INFO:utils.s3_utils:File unchanged, skipping: amato_pm/data_pipelines/unified_dataset/output/recent_customer_dataset.parquet\n",
            "INFO:utils.s3_utils:File unchanged, skipping: amato_pm/data_pipelines/unified_dataset/output/timeline_datasets_metadata.yaml\n",
            "INFO:utils.s3_utils:File unchanged, skipping: amato_pm/data_pipelines/unified_dataset/output/unified_customer_dataset.parquet\n",
            "INFO:__main__:‚úÖ Historical training data loaded from S3\n",
            "INFO:__main__:‚úÖ Loaded historical training dataset: (8514, 89)\n",
            "INFO:__main__:üìÖ This dataset contains historical data for model training\n",
            "INFO:__main__:üîß Preparing features for campaign_success...\n",
            "INFO:__main__:üîß Created synthetic campaign_success target\n",
            "INFO:__main__:‚úÖ Prepared 8514 customers with 17 features for campaign_success\n",
            "INFO:__main__:üéØ Training Campaign Success model...\n",
            "INFO:__main__:‚úÖ Campaign Success model trained successfully\n",
            "INFO:__main__:   Accuracy: 1.0000\n",
            "INFO:__main__:   F1 Score: 1.0000\n",
            "INFO:__main__:   CV Score: 1.0000 (+/- 0.0000)\n",
            "INFO:__main__:üîß Preparing features for budget_optimization...\n",
            "INFO:__main__:üîß Created synthetic optimal_budget target\n",
            "INFO:__main__:‚úÖ Prepared 8514 customers with 10 features for budget_optimization\n",
            "INFO:__main__:üéØ Training Budget Optimization model...\n",
            "INFO:__main__:‚úÖ Budget Optimization model trained successfully\n",
            "INFO:__main__:   MSE: 2017.3589\n",
            "INFO:__main__:   MAE: 3.2442\n",
            "INFO:__main__:   R¬≤: 0.9896\n",
            "INFO:__main__:   CV R¬≤: 0.9929 (+/- 0.0058)\n",
            "INFO:__main__:üíæ Saving models directly to S3...\n",
            "ERROR:__main__:‚ùå Failed to save models: module 'joblib' has no attribute 'dumps'\n",
            "INFO:__main__:============================================================\n",
            "INFO:__main__:üéâ TRAINING COMPLETED!\n",
            "INFO:__main__:============================================================\n",
            "INFO:__main__:üìä Trained 2 models on 8514 customers\n",
            "INFO:__main__:üîß Used features: ['campaign_success', 'budget_optimization']\n",
            "INFO:__main__:üíæ Models saved to: S3\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üéâ Campaign Optimization Training completed successfully!\n",
            "üìä Trained 2 models\n",
            "üîß Models ready for inference!\n"
          ]
        }
      ],
      "source": [
        "# Initialize and run the training pipeline\n",
        "if __name__ == \"__main__\":\n",
        "    pipeline = CampaignOptimizationPipeline()\n",
        "    success = pipeline.run_training_pipeline()\n",
        "    \n",
        "    if success:\n",
        "        print(\"\\nüéâ Campaign Optimization Training completed successfully!\")\n",
        "        print(f\"üìä Trained {len(pipeline.models)} models\")\n",
        "        print(\"üîß Models ready for inference!\")\n",
        "    else:\n",
        "        print(\"\\n‚ùå Training pipeline failed. Check logs for details.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
