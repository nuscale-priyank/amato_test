{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AMATO Production - Campaign Optimization Batch Inference Pipeline\n",
        "\n",
        "This notebook performs batch inference for campaign success prediction and budget optimization.\n",
        "\n",
        "**Author:** Data Science Team  \n",
        "**Date:** 2024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîß Using project root: /Users/priyankmavani/Desktop/apps/amato\n",
            "‚úÖ Successfully imported utils.s3_utils\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yaml\n",
        "import logging\n",
        "import os\n",
        "import sys\n",
        "import joblib\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Add project root to path for imports\n",
        "# Try multiple possible paths for Jupyter notebook compatibility\n",
        "possible_paths = [\n",
        "    Path.cwd(),  # Current working directory\n",
        "    Path.cwd().parent,  # Parent of current directory\n",
        "    Path.cwd().parent.parent,  # Grandparent of current directory\n",
        "    Path(__file__).parent.parent.parent if '__file__' in globals() else None  # If __file__ exists\n",
        "]\n",
        "\n",
        "# Filter out None values and find the one with utils folder\n",
        "project_root = None\n",
        "for path in possible_paths:\n",
        "    if path and (path / 'utils').exists():\n",
        "        project_root = path\n",
        "        break\n",
        "\n",
        "if project_root is None:\n",
        "    # Fallback: use current directory and hope for the best\n",
        "    project_root = Path.cwd()\n",
        "\n",
        "sys.path.append(str(project_root))\n",
        "print(f\"üîß Using project root: {project_root}\")\n",
        "\n",
        "try:\n",
        "    from utils.s3_utils import get_s3_manager\n",
        "    print(\"‚úÖ Successfully imported utils.s3_utils\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Failed to import utils.s3_utils: {e}\")\n",
        "    print(\"üîß Trying alternative import...\")\n",
        "    try:\n",
        "        # Try relative import\n",
        "        sys.path.append('.')\n",
        "        from utils.s3_utils import get_s3_manager\n",
        "        print(\"‚úÖ Successfully imported with relative path\")\n",
        "    except ImportError as e2:\n",
        "        print(f\"‚ùå Alternative import also failed: {e2}\")\n",
        "        raise\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Campaign Optimization Batch Inference Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CampaignOptimizationBatchInference:\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the Campaign Optimization Batch Inference Pipeline\"\"\"\n",
        "        self.models = {}\n",
        "        self.scalers = {}\n",
        "        self.metadata = {}\n",
        "        \n",
        "    def load_trained_models(self):\n",
        "        \"\"\"Load trained campaign optimization models from S3\"\"\"\n",
        "        logger.info(\"üì• Loading trained campaign optimization models...\")\n",
        "        \n",
        "        try:\n",
        "            s3_manager = get_s3_manager()\n",
        "            \n",
        "            # Create models directory if it doesn't exist\n",
        "            models_dir = 'models/campaign_optimization'\n",
        "            os.makedirs(models_dir, exist_ok=True)\n",
        "            \n",
        "            # Load Campaign Success model\n",
        "            success_model_path = f'{models_dir}/campaign_success_model.pkl'\n",
        "            success_scaler_path = f'{models_dir}/campaign_success_scaler.pkl'\n",
        "            \n",
        "            # Download Campaign Success model from S3 if not exists locally\n",
        "            if not os.path.exists(success_model_path):\n",
        "                logger.info(\"üì• Downloading Campaign Success model from S3...\")\n",
        "                try:\n",
        "                    # Use the correct S3 path structure\n",
        "                    s3_manager.download_file('amato_pm/models/campaign_optimization/campaign_success_model.pkl', success_model_path)\n",
        "                    logger.info(\"‚úÖ Downloaded Campaign Success model from S3\")\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"‚ö†Ô∏è  Failed to download Campaign Success model from S3: {e}\")\n",
        "            \n",
        "            # Download Campaign Success scaler from S3 if not exists locally\n",
        "            if not os.path.exists(success_scaler_path):\n",
        "                logger.info(\"üì• Downloading Campaign Success scaler from S3...\")\n",
        "                try:\n",
        "                    s3_manager.download_file('amato_pm/models/campaign_optimization/campaign_success_scaler.pkl', success_scaler_path)\n",
        "                    logger.info(\"‚úÖ Downloaded Campaign Success scaler from S3\")\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"‚ö†Ô∏è  Failed to download Campaign Success scaler from S3: {e}\")\n",
        "            \n",
        "            # Load Campaign Success model if available\n",
        "            if os.path.exists(success_model_path):\n",
        "                self.models['campaign_success'] = joblib.load(success_model_path)\n",
        "                if os.path.exists(success_scaler_path):\n",
        "                    self.scalers['campaign_success'] = joblib.load(success_scaler_path)\n",
        "                else:\n",
        "                    self.scalers['campaign_success'] = None\n",
        "                \n",
        "                # Create metadata with correct feature columns\n",
        "                self.metadata['campaign_success'] = {\n",
        "                    'feature_columns': [\n",
        "                        'recency_days', 'frequency', 'monetary_value',\n",
        "                        'avg_order_value', 'customer_lifetime_value',\n",
        "                        'campaign_count', 'avg_roas', 'avg_ctr', 'total_campaign_revenue',\n",
        "                        'campaign_response_rate', 'avg_ctr_lift', 'rfm_score',\n",
        "                        'total_sessions', 'total_events',\n",
        "                        'conversion_probability', 'churn_risk', 'upsell_potential'\n",
        "                    ],\n",
        "                    'model_type': 'RandomForestClassifier',\n",
        "                    'training_date': datetime.now().isoformat()\n",
        "                }\n",
        "                logger.info(\"‚úÖ Loaded Campaign Success model\")\n",
        "            else:\n",
        "                logger.warning(\"‚ö†Ô∏è  Campaign Success model not available\")\n",
        "            \n",
        "            # Load Budget Optimization model\n",
        "            budget_model_path = f'{models_dir}/budget_optimization_model.pkl'\n",
        "            budget_scaler_path = f'{models_dir}/budget_optimization_scaler.pkl'\n",
        "            \n",
        "            # Download Budget Optimization model from S3 if not exists locally\n",
        "            if not os.path.exists(budget_model_path):\n",
        "                logger.info(\"üì• Downloading Budget Optimization model from S3...\")\n",
        "                try:\n",
        "                    s3_manager.download_file('amato_pm/models/campaign_optimization/budget_optimization_model.pkl', budget_model_path)\n",
        "                    logger.info(\"‚úÖ Downloaded Budget Optimization model from S3\")\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"‚ö†Ô∏è  Failed to download Budget Optimization model from S3: {e}\")\n",
        "            \n",
        "            # Download Budget Optimization scaler from S3 if not exists locally\n",
        "            if not os.path.exists(budget_scaler_path):\n",
        "                logger.info(\"üì• Downloading Budget Optimization scaler from S3...\")\n",
        "                try:\n",
        "                    s3_manager.download_file('amato_pm/models/campaign_optimization/budget_optimization_scaler.pkl', budget_scaler_path)\n",
        "                    logger.info(\"‚úÖ Downloaded Budget Optimization scaler from S3\")\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"‚ö†Ô∏è  Failed to download Budget Optimization scaler from S3: {e}\")\n",
        "            \n",
        "            # Load Budget Optimization model if available\n",
        "            if os.path.exists(budget_model_path):\n",
        "                self.models['budget_optimization'] = joblib.load(budget_model_path)\n",
        "                if os.path.exists(budget_scaler_path):\n",
        "                    self.scalers['budget_optimization'] = joblib.load(budget_scaler_path)\n",
        "                else:\n",
        "                    self.scalers['budget_optimization'] = None\n",
        "                \n",
        "                # Create metadata with correct feature columns\n",
        "                self.metadata['budget_optimization'] = {\n",
        "                    'feature_columns': [\n",
        "                        'recency_days', 'frequency', 'monetary_value',\n",
        "                        'avg_order_value', 'customer_lifetime_value',\n",
        "                        'campaign_count', 'avg_roas', 'total_campaign_revenue',\n",
        "                        'rfm_score', 'conversion_probability'\n",
        "                    ],\n",
        "                    'model_type': 'RandomForestRegressor',\n",
        "                    'training_date': datetime.now().isoformat()\n",
        "                }\n",
        "                logger.info(\"‚úÖ Loaded Budget Optimization model\")\n",
        "            else:\n",
        "                logger.warning(\"‚ö†Ô∏è  Budget Optimization model not available\")\n",
        "            \n",
        "            logger.info(f\"‚úÖ Loaded {len(self.models)} models\")\n",
        "            \n",
        "            if len(self.models) == 0:\n",
        "                logger.error(\"‚ùå No models loaded. Please ensure models are available in S3.\")\n",
        "                raise Exception(\"No models available for inference\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            logger.error(f\"‚ùå Failed to load models: {e}\")\n",
        "            raise\n",
        "    \n",
        "    def load_inference_data(self, data_path=None):\n",
        "        \"\"\"Load recent inference data for campaign optimization\"\"\"\n",
        "        logger.info(\"üìä Loading recent inference data...\")\n",
        "        \n",
        "        try:\n",
        "            # Load recent inference data from S3\n",
        "            logger.info(\"üîç Loading recent inference data from S3...\")\n",
        "            s3_manager = get_s3_manager()\n",
        "            s3_manager.load_inference_data_from_s3()\n",
        "            logger.info(\"‚úÖ Recent inference data loaded from S3\")\n",
        "            \n",
        "            if data_path is None:\n",
        "                data_path = 'data_pipelines/unified_dataset/output/recent_customer_dataset.parquet'\n",
        "            \n",
        "            if os.path.exists(data_path):\n",
        "                df = pd.read_parquet(data_path)\n",
        "                logger.info(f\"‚úÖ Loaded recent inference data: {len(df)} customers\")\n",
        "                return df\n",
        "            else:\n",
        "                logger.error(f\"‚ùå Recent inference data not found at {data_path}\")\n",
        "                return None\n",
        "                \n",
        "        except Exception as e:\n",
        "            logger.error(f\"‚ùå Failed to load recent inference data: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def prepare_features(self, df, model_name):\n",
        "        \"\"\"Prepare features for inference\"\"\"\n",
        "        logger.info(f\"üîß Preparing features for {model_name} inference...\")\n",
        "        \n",
        "        if model_name not in self.metadata:\n",
        "            logger.error(f\"‚ùå No metadata found for {model_name}\")\n",
        "            return None\n",
        "        \n",
        "        # Get feature columns from metadata\n",
        "        feature_columns = self.metadata[model_name]['feature_columns']\n",
        "        \n",
        "        # Filter available features\n",
        "        available_features = [col for col in feature_columns if col in df.columns]\n",
        "        \n",
        "        if len(available_features) < 5:\n",
        "            logger.warning(f\"‚ö†Ô∏è  Only {len(available_features)} features available for {model_name}\")\n",
        "            \n",
        "        # Create feature matrix\n",
        "        X = df[available_features].copy()\n",
        "        \n",
        "        # Handle missing values\n",
        "        X = X.fillna(X.median())\n",
        "        \n",
        "        # Remove outliers using IQR method\n",
        "        for col in X.columns:\n",
        "            Q1 = X[col].quantile(0.25)\n",
        "            Q3 = X[col].quantile(0.75)\n",
        "            IQR = Q3 - Q1\n",
        "            lower_bound = Q1 - 1.5 * IQR\n",
        "            upper_bound = Q3 + 1.5 * IQR\n",
        "            X[col] = X[col].clip(lower_bound, upper_bound)\n",
        "        \n",
        "        logger.info(f\"‚úÖ Prepared {len(X)} customers for {model_name}\")\n",
        "        return X\n",
        "    \n",
        "    def perform_campaign_success_inference(self, df_features):\n",
        "        \"\"\"Perform campaign success inference\"\"\"\n",
        "        logger.info(\"üéØ Performing campaign success inference...\")\n",
        "        \n",
        "        if 'campaign_success' not in self.models:\n",
        "            logger.error(\"‚ùå Campaign Success model not loaded\")\n",
        "            return None\n",
        "        \n",
        "        # Scale features if scaler exists\n",
        "        if self.scalers['campaign_success'] is not None:\n",
        "            X_scaled = self.scalers['campaign_success'].transform(df_features)\n",
        "        else:\n",
        "            X_scaled = df_features\n",
        "        \n",
        "        # Predict success probability\n",
        "        success_probs = self.models['campaign_success'].predict_proba(X_scaled)[:, 1]\n",
        "        \n",
        "        # Create results dataframe\n",
        "        results = df_features.copy()\n",
        "        results['success_probability'] = success_probs\n",
        "        results['success_prediction'] = (success_probs > 0.5).astype(int)\n",
        "        results['success_category'] = pd.cut(success_probs, \n",
        "                                           bins=[0, 0.3, 0.7, 1.0], \n",
        "                                           labels=['Low', 'Medium', 'High'])\n",
        "        \n",
        "        logger.info(f\"‚úÖ Campaign success inference completed: {len(results)} predictions\")\n",
        "        return results\n",
        "    \n",
        "    def perform_budget_optimization_inference(self, df_features):\n",
        "        \"\"\"Perform budget optimization inference\"\"\"\n",
        "        logger.info(\"üéØ Performing budget optimization inference...\")\n",
        "        \n",
        "        if 'budget_optimization' not in self.models:\n",
        "            logger.error(\"‚ùå Budget Optimization model not loaded\")\n",
        "            return None\n",
        "        \n",
        "        # Scale features if scaler exists\n",
        "        if self.scalers['budget_optimization'] is not None:\n",
        "            X_scaled = self.scalers['budget_optimization'].transform(df_features)\n",
        "        else:\n",
        "            X_scaled = df_features\n",
        "        \n",
        "        # Predict optimal budget\n",
        "        optimal_budgets = self.models['budget_optimization'].predict(X_scaled)\n",
        "        \n",
        "        # Create results dataframe\n",
        "        results = df_features.copy()\n",
        "        results['optimal_budget'] = optimal_budgets\n",
        "        results['budget_category'] = pd.cut(optimal_budgets, \n",
        "                                          bins=5, \n",
        "                                          labels=['Very Low', 'Low', 'Medium', 'High', 'Very High'])\n",
        "        \n",
        "        logger.info(f\"‚úÖ Budget optimization inference completed: {len(results)} predictions\")\n",
        "        return results\n",
        "    \n",
        "    def save_inference_results(self, results, model_name):\n",
        "        \"\"\"Save inference results directly to S3\"\"\"\n",
        "        logger.info(f\"üíæ Saving {model_name} inference results...\")\n",
        "        \n",
        "        try:\n",
        "            s3_manager = get_s3_manager()\n",
        "            \n",
        "            # Save results directly to S3\n",
        "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "            results_key = f'models/campaign_optimization/inference_results/{model_name}_inference_results_{timestamp}.parquet'\n",
        "            \n",
        "            # Convert to parquet bytes and upload\n",
        "            results_bytes = results.to_parquet(index=False)\n",
        "            results_success = s3_manager.upload_bytes_direct(\n",
        "                results_bytes, results_key, 'application/octet-stream'\n",
        "            )\n",
        "            \n",
        "            # Generate and save report\n",
        "            report = self.generate_inference_report(results, model_name)\n",
        "            report_key = f'models/campaign_optimization/inference_results/{model_name}_inference_report_{timestamp}.yaml'\n",
        "            \n",
        "            report_success = s3_manager.upload_bytes_direct(\n",
        "                yaml.dump(report, default_flow_style=False).encode('utf-8'),\n",
        "                report_key, 'text/yaml'\n",
        "            )\n",
        "            \n",
        "            if results_success and report_success:\n",
        "                logger.info(f\"‚úÖ {model_name} results uploaded directly to S3\")\n",
        "                return results_key, report_key\n",
        "            else:\n",
        "                logger.warning(f\"‚ö†Ô∏è  Some {model_name} results failed to upload to S3\")\n",
        "                return None, None\n",
        "                \n",
        "        except Exception as e:\n",
        "            logger.error(f\"‚ùå Failed to save {model_name} results: {e}\")\n",
        "            return None, None\n",
        "    \n",
        "    def generate_inference_report(self, results, model_name):\n",
        "        \"\"\"Generate inference report\"\"\"\n",
        "        logger.info(f\"üìã Generating {model_name} inference report...\")\n",
        "        \n",
        "        if model_name == 'campaign_success':\n",
        "            report = {\n",
        "                'model_name': model_name,\n",
        "                'inference_date': datetime.now().isoformat(),\n",
        "                'total_customers': len(results),\n",
        "                'success_probability_stats': {\n",
        "                    'mean': float(results['success_probability'].mean()),\n",
        "                    'median': float(results['success_probability'].median()),\n",
        "                    'std': float(results['success_probability'].std())\n",
        "                },\n",
        "                'success_prediction_distribution': results['success_prediction'].value_counts().to_dict(),\n",
        "                'success_category_distribution': results['success_category'].value_counts().to_dict(),\n",
        "                'feature_summary': {\n",
        "                    'total_features': len(results.columns),\n",
        "                    'numeric_features': len(results.select_dtypes(include=[np.number]).columns),\n",
        "                    'categorical_features': len(results.select_dtypes(include=['object']).columns)\n",
        "                }\n",
        "            }\n",
        "        elif model_name == 'budget_optimization':\n",
        "            report = {\n",
        "                'model_name': model_name,\n",
        "                'inference_date': datetime.now().isoformat(),\n",
        "                'total_customers': len(results),\n",
        "                'optimal_budget_stats': {\n",
        "                    'mean': float(results['optimal_budget'].mean()),\n",
        "                    'median': float(results['optimal_budget'].median()),\n",
        "                    'std': float(results['optimal_budget'].std())\n",
        "                },\n",
        "                'budget_category_distribution': results['budget_category'].value_counts().to_dict(),\n",
        "                'feature_summary': {\n",
        "                    'total_features': len(results.columns),\n",
        "                    'numeric_features': len(results.select_dtypes(include=[np.number]).columns),\n",
        "                    'categorical_features': len(results.select_dtypes(include=['object']).columns)\n",
        "                }\n",
        "            }\n",
        "        else:\n",
        "            report = {\n",
        "                'model_name': model_name,\n",
        "                'inference_date': datetime.now().isoformat(),\n",
        "                'total_customers': len(results),\n",
        "                'feature_summary': {\n",
        "                    'total_features': len(results.columns),\n",
        "                    'numeric_features': len(results.select_dtypes(include=[np.number]).columns),\n",
        "                    'categorical_features': len(results.select_dtypes(include=['object']).columns)\n",
        "                }\n",
        "            }\n",
        "        \n",
        "        return report\n",
        "    \n",
        "    def create_inference_visualizations(self, results, model_name):\n",
        "        \"\"\"Create inference visualizations and upload directly to S3\"\"\"\n",
        "        logger.info(f\"üìä Creating {model_name} inference visualizations...\")\n",
        "        \n",
        "        try:\n",
        "            s3_manager = get_s3_manager()\n",
        "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "            \n",
        "            if model_name == 'campaign_success':\n",
        "                # Success probability distribution\n",
        "                fig1 = px.histogram(\n",
        "                    results, x='success_probability',\n",
        "                    title=f'{model_name.replace(\"_\", \" \").title()} Success Probability Distribution',\n",
        "                    labels={'success_probability': 'Success Probability', 'count': 'Customer Count'}\n",
        "                )\n",
        "                \n",
        "                # Success category distribution\n",
        "                fig2 = px.pie(\n",
        "                    values=results['success_category'].value_counts().values,\n",
        "                    names=results['success_category'].value_counts().index,\n",
        "                    title=f'{model_name.replace(\"_\", \" \").title()} Success Category Distribution'\n",
        "                )\n",
        "                \n",
        "                # Upload visualizations directly to S3\n",
        "                html1_key = f'models/campaign_optimization/inference_results/{model_name}_success_probability_{timestamp}.html'\n",
        "                html2_key = f'models/campaign_optimization/inference_results/{model_name}_success_categories_{timestamp}.html'\n",
        "                \n",
        "            elif model_name == 'budget_optimization':\n",
        "                # Optimal budget distribution\n",
        "                fig1 = px.histogram(\n",
        "                    results, x='optimal_budget',\n",
        "                    title=f'{model_name.replace(\"_\", \" \").title()} Optimal Budget Distribution',\n",
        "                    labels={'optimal_budget': 'Optimal Budget', 'count': 'Customer Count'}\n",
        "                )\n",
        "                \n",
        "                # Budget category distribution\n",
        "                fig2 = px.pie(\n",
        "                    values=results['budget_category'].value_counts().values,\n",
        "                    names=results['budget_category'].value_counts().index,\n",
        "                    title=f'{model_name.replace(\"_\", \" \").title()} Budget Category Distribution'\n",
        "                )\n",
        "                \n",
        "                # Upload visualizations directly to S3\n",
        "                html1_key = f'models/campaign_optimization/inference_results/{model_name}_budget_distribution_{timestamp}.html'\n",
        "                html2_key = f'models/campaign_optimization/inference_results/{model_name}_budget_categories_{timestamp}.html'\n",
        "            \n",
        "            # Convert figures to HTML and upload\n",
        "            html1_bytes = fig1.to_html().encode('utf-8')\n",
        "            html2_bytes = fig2.to_html().encode('utf-8')\n",
        "            \n",
        "            s3_manager.upload_bytes_direct(html1_bytes, html1_key, 'text/html')\n",
        "            s3_manager.upload_bytes_direct(html2_bytes, html2_key, 'text/html')\n",
        "            \n",
        "            logger.info(f\"‚úÖ {model_name} visualizations uploaded directly to S3\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            logger.error(f\"‚ùå Failed to create {model_name} visualizations: {e}\")\n",
        "    \n",
        "    def run_batch_inference(self, data_path=None, models=None):\n",
        "        \"\"\"Run batch inference for all models\"\"\"\n",
        "        logger.info(\"üöÄ Starting Campaign Optimization Batch Inference...\")\n",
        "        \n",
        "        try:\n",
        "            # Load models\n",
        "            self.load_trained_models()\n",
        "            \n",
        "            # Load data\n",
        "            df = self.load_inference_data(data_path)\n",
        "            if df is None:\n",
        "                raise Exception(\"Failed to load inference data\")\n",
        "            \n",
        "            # Determine which models to run\n",
        "            if models is None:\n",
        "                models = list(self.models.keys())\n",
        "            \n",
        "            all_results = {}\n",
        "            \n",
        "            for model_name in models:\n",
        "                if model_name not in self.models:\n",
        "                    logger.warning(f\"‚ö†Ô∏è Model {model_name} not found, skipping...\")\n",
        "                    continue\n",
        "                \n",
        "                # Prepare features\n",
        "                df_features = self.prepare_features(df, model_name)\n",
        "                \n",
        "                if df_features is None or len(df_features) == 0:\n",
        "                    logger.warning(f\"‚ö†Ô∏è  No features prepared for {model_name}, skipping...\")\n",
        "                    continue\n",
        "                \n",
        "                # Perform inference\n",
        "                if model_name == 'campaign_success':\n",
        "                    results = self.perform_campaign_success_inference(df_features)\n",
        "                elif model_name == 'budget_optimization':\n",
        "                    results = self.perform_budget_optimization_inference(df_features)\n",
        "                else:\n",
        "                    logger.warning(f\"‚ö†Ô∏è  Unknown model: {model_name}\")\n",
        "                    continue\n",
        "                \n",
        "                if results is not None:\n",
        "                    # Save results\n",
        "                    results_file, report_file = self.save_inference_results(results, model_name)\n",
        "                    \n",
        "                    # Create visualizations\n",
        "                    self.create_inference_visualizations(results, model_name)\n",
        "                    \n",
        "                    all_results[model_name] = results\n",
        "                    \n",
        "                    logger.info(f\"‚úÖ {model_name} batch inference completed\")\n",
        "            \n",
        "            logger.info(\"=\" * 60)\n",
        "            logger.info(\"üéâ BATCH INFERENCE COMPLETED!\")\n",
        "            logger.info(\"=\" * 60)\n",
        "            logger.info(f\"üìä Processed {len(df)} customers\")\n",
        "            logger.info(f\"üéØ Ran inference for {len(all_results)} models\")\n",
        "            \n",
        "            return all_results\n",
        "            \n",
        "        except Exception as e:\n",
        "            logger.error(f\"‚ùå Error in batch inference: {e}\")\n",
        "            raise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run the Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:üöÄ Starting Campaign Optimization Batch Inference...\n",
            "INFO:__main__:üì• Loading trained campaign optimization models...\n",
            "INFO:__main__:‚úÖ Loaded Campaign Success model\n",
            "INFO:__main__:‚úÖ Loaded Budget Optimization model\n",
            "INFO:__main__:‚úÖ Loaded 2 models\n",
            "INFO:__main__:üìä Loading recent inference data...\n",
            "INFO:__main__:üîç Loading recent inference data from S3...\n",
            "INFO:utils.s3_utils:Loading recent inference data from S3 with smart caching (last 3 months)...\n",
            "INFO:utils.s3_utils:Loading data newer than 2025-06-06\n",
            "INFO:utils.s3_utils:File unchanged, skipping: amato_pm/data_pipelines/unified_dataset/output/recent_customer_dataset.parquet\n",
            "INFO:utils.s3_utils:File unchanged, skipping: amato_pm/data_pipelines/unified_dataset/output/timeline_datasets_metadata.yaml\n",
            "INFO:utils.s3_utils:File unchanged, skipping: amato_pm/data_pipelines/unified_dataset/output/unified_customer_dataset.parquet\n",
            "INFO:__main__:‚úÖ Recent inference data loaded from S3\n",
            "INFO:__main__:‚úÖ Loaded recent inference data: 1123 customers\n",
            "INFO:__main__:üîß Preparing features for campaign_success inference...\n",
            "INFO:__main__:‚úÖ Prepared 1123 customers for campaign_success\n",
            "INFO:__main__:üéØ Performing campaign success inference...\n",
            "INFO:__main__:‚úÖ Campaign success inference completed: 1123 predictions\n",
            "INFO:__main__:üíæ Saving campaign_success inference results...\n",
            "INFO:utils.s3_utils:Uploading bytes directly to s3://nuscale-data-services-public/models/campaign_optimization/inference_results/campaign_success_inference_results_20250904_113455.parquet\n",
            "INFO:utils.s3_utils:Successfully uploaded bytes to s3://nuscale-data-services-public/models/campaign_optimization/inference_results/campaign_success_inference_results_20250904_113455.parquet\n",
            "INFO:__main__:üìã Generating campaign_success inference report...\n",
            "INFO:utils.s3_utils:Uploading bytes directly to s3://nuscale-data-services-public/models/campaign_optimization/inference_results/campaign_success_inference_report_20250904_113455.yaml\n",
            "INFO:utils.s3_utils:Successfully uploaded bytes to s3://nuscale-data-services-public/models/campaign_optimization/inference_results/campaign_success_inference_report_20250904_113455.yaml\n",
            "INFO:__main__:‚úÖ campaign_success results uploaded directly to S3\n",
            "INFO:__main__:üìä Creating campaign_success inference visualizations...\n",
            "INFO:utils.s3_utils:Uploading bytes directly to s3://nuscale-data-services-public/models/campaign_optimization/inference_results/campaign_success_success_probability_20250904_113456.html\n",
            "INFO:utils.s3_utils:Successfully uploaded bytes to s3://nuscale-data-services-public/models/campaign_optimization/inference_results/campaign_success_success_probability_20250904_113456.html\n",
            "INFO:utils.s3_utils:Uploading bytes directly to s3://nuscale-data-services-public/models/campaign_optimization/inference_results/campaign_success_success_categories_20250904_113456.html\n",
            "INFO:utils.s3_utils:Successfully uploaded bytes to s3://nuscale-data-services-public/models/campaign_optimization/inference_results/campaign_success_success_categories_20250904_113456.html\n",
            "INFO:__main__:‚úÖ campaign_success visualizations uploaded directly to S3\n",
            "INFO:__main__:‚úÖ campaign_success batch inference completed\n",
            "INFO:__main__:üîß Preparing features for budget_optimization inference...\n",
            "INFO:__main__:‚úÖ Prepared 1123 customers for budget_optimization\n",
            "INFO:__main__:üéØ Performing budget optimization inference...\n",
            "INFO:__main__:‚úÖ Budget optimization inference completed: 1123 predictions\n",
            "INFO:__main__:üíæ Saving budget_optimization inference results...\n",
            "INFO:utils.s3_utils:Uploading bytes directly to s3://nuscale-data-services-public/models/campaign_optimization/inference_results/budget_optimization_inference_results_20250904_113501.parquet\n",
            "INFO:utils.s3_utils:Successfully uploaded bytes to s3://nuscale-data-services-public/models/campaign_optimization/inference_results/budget_optimization_inference_results_20250904_113501.parquet\n",
            "INFO:__main__:üìã Generating budget_optimization inference report...\n",
            "INFO:utils.s3_utils:Uploading bytes directly to s3://nuscale-data-services-public/models/campaign_optimization/inference_results/budget_optimization_inference_report_20250904_113501.yaml\n",
            "INFO:utils.s3_utils:Successfully uploaded bytes to s3://nuscale-data-services-public/models/campaign_optimization/inference_results/budget_optimization_inference_report_20250904_113501.yaml\n",
            "INFO:__main__:‚úÖ budget_optimization results uploaded directly to S3\n",
            "INFO:__main__:üìä Creating budget_optimization inference visualizations...\n",
            "INFO:utils.s3_utils:Uploading bytes directly to s3://nuscale-data-services-public/models/campaign_optimization/inference_results/budget_optimization_budget_distribution_20250904_113501.html\n",
            "INFO:utils.s3_utils:Successfully uploaded bytes to s3://nuscale-data-services-public/models/campaign_optimization/inference_results/budget_optimization_budget_distribution_20250904_113501.html\n",
            "INFO:utils.s3_utils:Uploading bytes directly to s3://nuscale-data-services-public/models/campaign_optimization/inference_results/budget_optimization_budget_categories_20250904_113501.html\n",
            "INFO:utils.s3_utils:Successfully uploaded bytes to s3://nuscale-data-services-public/models/campaign_optimization/inference_results/budget_optimization_budget_categories_20250904_113501.html\n",
            "INFO:__main__:‚úÖ budget_optimization visualizations uploaded directly to S3\n",
            "INFO:__main__:‚úÖ budget_optimization batch inference completed\n",
            "INFO:__main__:============================================================\n",
            "INFO:__main__:üéâ BATCH INFERENCE COMPLETED!\n",
            "INFO:__main__:============================================================\n",
            "INFO:__main__:üìä Processed 1123 customers\n",
            "INFO:__main__:üéØ Ran inference for 2 models\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üéâ Campaign Optimization Batch Inference completed successfully!\n",
            "üìä Results saved to models/campaign_optimization/inference_results/\n",
            "üìà Ready for campaign optimization analysis!\n"
          ]
        }
      ],
      "source": [
        "# Initialize and run the pipeline\n",
        "if __name__ == \"__main__\":\n",
        "    inference = CampaignOptimizationBatchInference()\n",
        "    results = inference.run_batch_inference()\n",
        "    \n",
        "    print(\"\\nüéâ Campaign Optimization Batch Inference completed successfully!\")\n",
        "    print(f\"üìä Results saved to models/campaign_optimization/inference_results/\")\n",
        "    print(\"üìà Ready for campaign optimization analysis!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
