{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AMATO Production - Forecasting Batch Inference Pipeline\n",
        "\n",
        "This notebook performs batch inference for revenue and CTR forecasting.\n",
        "\n",
        "**Author:** Data Science Team  \n",
        "**Date:** 2024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîß Using project root: /Users/priyankmavani/Desktop/apps/amato\n",
            "‚úÖ Successfully imported utils.s3_utils\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yaml\n",
        "import logging\n",
        "import os\n",
        "import sys\n",
        "import joblib\n",
        "from pathlib import Path\n",
        "from datetime import datetime, timedelta\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Add project root to path for imports\n",
        "# Try multiple possible paths for Jupyter notebook compatibility\n",
        "possible_paths = [\n",
        "    Path.cwd(),  # Current working directory\n",
        "    Path.cwd().parent,  # Parent of current directory\n",
        "    Path.cwd().parent.parent,  # Grandparent of current directory\n",
        "    Path(__file__).parent.parent.parent if '__file__' in globals() else None  # If __file__ exists\n",
        "]\n",
        "\n",
        "# Filter out None values and find the one with utils folder\n",
        "project_root = None\n",
        "for path in possible_paths:\n",
        "    if path and (path / 'utils').exists():\n",
        "        project_root = path\n",
        "        break\n",
        "\n",
        "if project_root is None:\n",
        "    # Fallback: use current directory and hope for the best\n",
        "    project_root = Path.cwd()\n",
        "\n",
        "sys.path.append(str(project_root))\n",
        "print(f\"üîß Using project root: {project_root}\")\n",
        "\n",
        "try:\n",
        "    from utils.s3_utils import get_s3_manager\n",
        "    print(\"‚úÖ Successfully imported utils.s3_utils\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Failed to import utils.s3_utils: {e}\")\n",
        "    print(\"üîß Trying alternative import...\")\n",
        "    try:\n",
        "        # Try relative import\n",
        "        sys.path.append('.')\n",
        "        from utils.s3_utils import get_s3_manager\n",
        "        print(\"‚úÖ Successfully imported with relative path\")\n",
        "    except ImportError as e2:\n",
        "        print(f\"‚ùå Alternative import also failed: {e2}\")\n",
        "        raise\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Forecasting Batch Inference Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ForecastingBatchInference:\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the Forecasting Batch Inference Pipeline\"\"\"\n",
        "        self.models = {}\n",
        "        self.scalers = {}\n",
        "        self.metadata = {}\n",
        "        \n",
        "    def load_trained_models(self):\n",
        "        \"\"\"Load trained forecasting models from S3\"\"\"\n",
        "        logger.info(\"üì• Loading trained forecasting models...\")\n",
        "        \n",
        "        try:\n",
        "            s3_manager = get_s3_manager()\n",
        "            \n",
        "            # Create models directory if it doesn't exist\n",
        "            models_dir = 'models/forecasting'\n",
        "            os.makedirs(models_dir, exist_ok=True)\n",
        "            \n",
        "            # Load Revenue Forecasting model\n",
        "            revenue_model_path = f'{models_dir}/revenue_forecasting_model.pkl'\n",
        "            revenue_scaler_path = f'{models_dir}/revenue_forecasting_scaler.pkl'\n",
        "            \n",
        "            # Download Revenue Forecasting model from S3 if not exists locally\n",
        "            if not os.path.exists(revenue_model_path):\n",
        "                logger.info(\"üì• Downloading Revenue Forecasting model from S3...\")\n",
        "                try:\n",
        "                    s3_manager.download_file('amato_pm/models/forecasting/revenue_forecasting_model.pkl', revenue_model_path)\n",
        "                    logger.info(\"‚úÖ Downloaded Revenue Forecasting model from S3\")\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"‚ö†Ô∏è  Failed to download Revenue Forecasting model from S3: {e}\")\n",
        "            \n",
        "            # Download Revenue Forecasting scaler from S3 if not exists locally\n",
        "            if not os.path.exists(revenue_scaler_path):\n",
        "                logger.info(\"üì• Downloading Revenue Forecasting scaler from S3...\")\n",
        "                try:\n",
        "                    s3_manager.download_file('amato_pm/models/forecasting/revenue_forecasting_scaler.pkl', revenue_scaler_path)\n",
        "                    logger.info(\"‚úÖ Downloaded Revenue Forecasting scaler from S3\")\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"‚ö†Ô∏è  Failed to download Revenue Forecasting scaler from S3: {e}\")\n",
        "            \n",
        "            # Load Revenue Forecasting model if available\n",
        "            if os.path.exists(revenue_model_path):\n",
        "                self.models['revenue'] = joblib.load(revenue_model_path)\n",
        "                if os.path.exists(revenue_scaler_path):\n",
        "                    self.scalers['revenue'] = joblib.load(revenue_scaler_path)\n",
        "                else:\n",
        "                    self.scalers['revenue'] = None\n",
        "                \n",
        "                # Create metadata with correct feature columns\n",
        "                self.metadata['revenue'] = {\n",
        "                    'feature_columns': [\n",
        "                        'rfm_score', 'frequency', 'avg_order_value', 'days_since_last_purchase',\n",
        "                        'day_of_week', 'month', 'quarter', 'year', 'revenue_lag_1',\n",
        "                        'revenue_lag_7', 'revenue_lag_30', 'revenue_ma_7', 'revenue_ma_30',\n",
        "                        'customer_age_days'\n",
        "                    ],\n",
        "                    'model_type': 'RandomForestRegressor',\n",
        "                    'training_date': datetime.now().isoformat()\n",
        "                }\n",
        "                logger.info(\"‚úÖ Loaded Revenue Forecasting model\")\n",
        "            else:\n",
        "                logger.warning(\"‚ö†Ô∏è  Revenue Forecasting model not available\")\n",
        "            \n",
        "            # Load CTR Forecasting model\n",
        "            ctr_model_path = f'{models_dir}/ctr_forecasting_model.pkl'\n",
        "            ctr_scaler_path = f'{models_dir}/ctr_forecasting_scaler.pkl'\n",
        "            \n",
        "            # Download CTR Forecasting model from S3 if not exists locally\n",
        "            if not os.path.exists(ctr_model_path):\n",
        "                logger.info(\"üì• Downloading CTR Forecasting model from S3...\")\n",
        "                try:\n",
        "                    s3_manager.download_file('amato_pm/models/forecasting/ctr_forecasting_model.pkl', ctr_model_path)\n",
        "                    logger.info(\"‚úÖ Downloaded CTR Forecasting model from S3\")\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"‚ö†Ô∏è  Failed to download CTR Forecasting model from S3: {e}\")\n",
        "            \n",
        "            # Download CTR Forecasting scaler from S3 if not exists locally\n",
        "            if not os.path.exists(ctr_scaler_path):\n",
        "                logger.info(\"üì• Downloading CTR Forecasting scaler from S3...\")\n",
        "                try:\n",
        "                    s3_manager.download_file('amato_pm/models/forecasting/ctr_forecasting_scaler.pkl', ctr_scaler_path)\n",
        "                    logger.info(\"‚úÖ Downloaded CTR Forecasting scaler from S3\")\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"‚ö†Ô∏è  Failed to download CTR Forecasting scaler from S3: {e}\")\n",
        "            \n",
        "            # Load CTR Forecasting model if available\n",
        "            if os.path.exists(ctr_model_path):\n",
        "                self.models['ctr'] = joblib.load(ctr_model_path)\n",
        "                if os.path.exists(ctr_scaler_path):\n",
        "                    self.scalers['ctr'] = joblib.load(ctr_scaler_path)\n",
        "                else:\n",
        "                    self.scalers['ctr'] = None\n",
        "                \n",
        "                # Create metadata with correct feature columns\n",
        "                self.metadata['ctr'] = {\n",
        "                    'feature_columns': [\n",
        "                        'rfm_score', 'frequency', 'avg_order_value', 'day_of_week',\n",
        "                        'month', 'quarter', 'year', 'ctr_lag_1', 'ctr_ma_7',\n",
        "                        'customer_age_days'\n",
        "                    ],\n",
        "                    'model_type': 'RandomForestRegressor',\n",
        "                    'training_date': datetime.now().isoformat()\n",
        "                }\n",
        "                logger.info(\"‚úÖ Loaded CTR Forecasting model\")\n",
        "            else:\n",
        "                logger.warning(\"‚ö†Ô∏è  CTR Forecasting model not available\")\n",
        "            \n",
        "            logger.info(f\"‚úÖ Loaded {len(self.models)} models\")\n",
        "            \n",
        "            if len(self.models) == 0:\n",
        "                logger.error(\"‚ùå No models loaded. Please ensure models are available in S3.\")\n",
        "                raise Exception(\"No models available for inference\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            logger.error(f\"‚ùå Failed to load models: {e}\")\n",
        "            raise\n",
        "    \n",
        "    def load_inference_data(self, data_path=None):\n",
        "        \"\"\"Load recent inference data for forecasting\"\"\"\n",
        "        logger.info(\"üìä Loading recent inference data...\")\n",
        "        \n",
        "        try:\n",
        "            # Load recent inference data from S3\n",
        "            logger.info(\"üîç Loading recent inference data from S3...\")\n",
        "            s3_manager = get_s3_manager()\n",
        "            s3_manager.load_inference_data_from_s3()\n",
        "            logger.info(\"‚úÖ Recent inference data loaded from S3\")\n",
        "            \n",
        "            if data_path is None:\n",
        "                data_path = 'data_pipelines/unified_dataset/output/recent_customer_dataset.parquet'\n",
        "            \n",
        "            if os.path.exists(data_path):\n",
        "                df = pd.read_parquet(data_path)\n",
        "                logger.info(f\"‚úÖ Loaded recent inference data: {len(df)} customers\")\n",
        "                return df\n",
        "            else:\n",
        "                logger.error(f\"‚ùå Recent inference data not found at {data_path}\")\n",
        "                return None\n",
        "                \n",
        "        except Exception as e:\n",
        "            logger.error(f\"‚ùå Failed to load recent inference data: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def prepare_features(self, df, target_col):\n",
        "        \"\"\"Prepare features for forecasting inference\"\"\"\n",
        "        logger.info(f\"ÔøΩÔøΩ Preparing features for {target_col} inference...\")\n",
        "        \n",
        "        # Use EXACTLY the same features that were used during training\n",
        "        if target_col == 'revenue':\n",
        "            feature_columns = [\n",
        "                'recency_days', 'frequency', 'monetary_value',\n",
        "                'avg_order_value', 'total_orders', 'days_since_first_order',\n",
        "                'customer_lifetime_value', 'avg_days_between_orders',\n",
        "                'order_count_30d', 'order_count_90d', 'order_count_365d',\n",
        "                'revenue_30d', 'revenue_90d', 'revenue_365d'\n",
        "            ]\n",
        "        elif target_col == 'ctr':\n",
        "            feature_columns = [\n",
        "                'recency_days', 'frequency', 'monetary_value',\n",
        "                'avg_order_value', 'total_orders', 'days_since_first_order',\n",
        "                'customer_lifetime_value', 'avg_days_between_orders',\n",
        "                'order_count_30d', 'order_count_90d', 'order_count_365d',\n",
        "                'revenue_30d', 'revenue_90d', 'revenue_365d'\n",
        "            ]\n",
        "        else:\n",
        "            logger.error(f\"‚ùå Unknown target column: {target_col}\")\n",
        "            return None\n",
        "        \n",
        "        # Filter available features\n",
        "        available_features = [col for col in feature_columns if col in df.columns]\n",
        "        \n",
        "        if len(available_features) < 5:\n",
        "            logger.warning(f\"‚ö†Ô∏è  Only {len(available_features)} features available for {target_col}\")\n",
        "            \n",
        "        # Create feature matrix with EXACTLY the same features used in training\n",
        "        X = df[available_features].copy()\n",
        "        \n",
        "        # Handle missing values\n",
        "        X = X.fillna(X.median())\n",
        "        \n",
        "        # Remove outliers using IQR method\n",
        "        for col in X.columns:\n",
        "            Q1 = X[col].quantile(0.25)\n",
        "            Q3 = X[col].quantile(0.75)\n",
        "            IQR = Q3 - Q1\n",
        "            lower_bound = Q1 - 1.5 * IQR\n",
        "            upper_bound = Q3 + 1.5 * IQR\n",
        "            X[col] = X[col].clip(lower_bound, upper_bound)\n",
        "        \n",
        "        logger.info(f\"‚úÖ Prepared {len(X)} customers with {len(X.columns)} features for {target_col}\")\n",
        "        return X\n",
        "    \n",
        "    def perform_revenue_forecasting(self, df_features):\n",
        "        \"\"\"Perform revenue forecasting inference\"\"\"\n",
        "        logger.info(\"üéØ Performing revenue forecasting inference...\")\n",
        "        \n",
        "        if 'revenue' not in self.models:\n",
        "            logger.error(\"‚ùå Revenue Forecasting model not loaded\")\n",
        "            return None\n",
        "        \n",
        "        # Scale features if scaler exists\n",
        "        if self.scalers['revenue'] is not None:\n",
        "            X_scaled = self.scalers['revenue'].transform(df_features)\n",
        "        else:\n",
        "            X_scaled = df_features\n",
        "        \n",
        "        # Predict revenue\n",
        "        predicted_revenue = self.models['revenue'].predict(X_scaled)\n",
        "        \n",
        "        # Create results dataframe\n",
        "        results = df_features.copy()\n",
        "        results['predicted_revenue'] = predicted_revenue\n",
        "        results['revenue_category'] = pd.cut(predicted_revenue, \n",
        "                                           bins=5, \n",
        "                                           labels=['Very Low', 'Low', 'Medium', 'High', 'Very High'])\n",
        "        \n",
        "        logger.info(f\"‚úÖ Revenue forecasting completed: {len(results)} predictions\")\n",
        "        return results\n",
        "    \n",
        "    def perform_ctr_forecasting(self, df_features):\n",
        "        \"\"\"Perform CTR forecasting inference\"\"\"\n",
        "        logger.info(\"üéØ Performing CTR forecasting inference...\")\n",
        "        \n",
        "        if 'ctr' not in self.models:\n",
        "            logger.error(\"‚ùå CTR Forecasting model not loaded\")\n",
        "            return None\n",
        "        \n",
        "        # Scale features if scaler exists\n",
        "        if self.scalers['ctr'] is not None:\n",
        "            X_scaled = self.scalers['ctr'].transform(df_features)\n",
        "        else:\n",
        "            X_scaled = df_features\n",
        "        \n",
        "        # Predict CTR\n",
        "        predicted_ctr = self.models['ctr'].predict(X_scaled)\n",
        "        \n",
        "        # Create results dataframe\n",
        "        results = df_features.copy()\n",
        "        results['predicted_ctr'] = predicted_ctr\n",
        "        results['ctr_category'] = pd.cut(predicted_ctr, \n",
        "                                       bins=5, \n",
        "                                       labels=['Very Low', 'Low', 'Medium', 'High', 'Very High'])\n",
        "        \n",
        "        logger.info(f\"‚úÖ CTR forecasting completed: {len(results)} predictions\")\n",
        "        return results\n",
        "    \n",
        "    def save_inference_results(self, results, model_name):\n",
        "        \"\"\"Save inference results directly to S3\"\"\"\n",
        "        logger.info(f\"üíæ Saving {model_name} inference results...\")\n",
        "        \n",
        "        try:\n",
        "            s3_manager = get_s3_manager()\n",
        "            \n",
        "            # Save results directly to S3\n",
        "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "            results_key = f'models/forecasting/inference_results/{model_name}_inference_results_{timestamp}.parquet'\n",
        "            \n",
        "            # Convert to parquet bytes and upload\n",
        "            results_bytes = results.to_parquet(index=False)\n",
        "            results_success = s3_manager.upload_bytes_direct(\n",
        "                results_bytes, results_key, 'application/octet-stream'\n",
        "            )\n",
        "            \n",
        "            # Generate and save report\n",
        "            report = self.generate_inference_report(results, model_name)\n",
        "            report_key = f'models/forecasting/inference_results/{model_name}_inference_report_{timestamp}.yaml'\n",
        "            \n",
        "            report_success = s3_manager.upload_bytes_direct(\n",
        "                yaml.dump(report, default_flow_style=False).encode('utf-8'),\n",
        "                report_key, 'text/yaml'\n",
        "            )\n",
        "            \n",
        "            if results_success and report_success:\n",
        "                logger.info(f\"‚úÖ {model_name} results uploaded directly to S3\")\n",
        "                return results_key, report_key\n",
        "            else:\n",
        "                logger.warning(f\"‚ö†Ô∏è  Some {model_name} results failed to upload to S3\")\n",
        "                return None, None\n",
        "                \n",
        "        except Exception as e:\n",
        "            logger.error(f\"‚ùå Failed to save {model_name} results: {e}\")\n",
        "            return None, None\n",
        "    \n",
        "    def generate_inference_report(self, results, model_name):\n",
        "        \"\"\"Generate inference report\"\"\"\n",
        "        logger.info(f\"üìã Generating {model_name} inference report...\")\n",
        "        \n",
        "        if model_name == 'revenue':\n",
        "            report = {\n",
        "                'model_name': model_name,\n",
        "                'inference_date': datetime.now().isoformat(),\n",
        "                'total_customers': len(results),\n",
        "                'predicted_revenue_stats': {\n",
        "                    'mean': float(results['predicted_revenue'].mean()),\n",
        "                    'median': float(results['predicted_revenue'].median()),\n",
        "                    'std': float(results['predicted_revenue'].std())\n",
        "                },\n",
        "                'revenue_category_distribution': results['revenue_category'].value_counts().to_dict(),\n",
        "                'feature_summary': {\n",
        "                    'total_features': len(results.columns),\n",
        "                    'numeric_features': len(results.select_dtypes(include=[np.number]).columns),\n",
        "                    'categorical_features': len(results.select_dtypes(include=['object']).columns)\n",
        "                }\n",
        "            }\n",
        "        elif model_name == 'ctr':\n",
        "            report = {\n",
        "                'model_name': model_name,\n",
        "                'inference_date': datetime.now().isoformat(),\n",
        "                'total_customers': len(results),\n",
        "                'predicted_ctr_stats': {\n",
        "                    'mean': float(results['predicted_ctr'].mean()),\n",
        "                    'median': float(results['predicted_ctr'].median()),\n",
        "                    'std': float(results['predicted_ctr'].std())\n",
        "                },\n",
        "                'ctr_category_distribution': results['ctr_category'].value_counts().to_dict(),\n",
        "                'feature_summary': {\n",
        "                    'total_features': len(results.columns),\n",
        "                    'numeric_features': len(results.select_dtypes(include=[np.number]).columns),\n",
        "                    'categorical_features': len(results.select_dtypes(include=['object']).columns)\n",
        "                }\n",
        "            }\n",
        "        else:\n",
        "            report = {\n",
        "                'model_name': model_name,\n",
        "                'inference_date': datetime.now().isoformat(),\n",
        "                'total_customers': len(results),\n",
        "                'feature_summary': {\n",
        "                    'total_features': len(results.columns),\n",
        "                    'numeric_features': len(results.select_dtypes(include=[np.number]).columns),\n",
        "                    'categorical_features': len(results.select_dtypes(include=['object']).columns)\n",
        "                }\n",
        "            }\n",
        "        \n",
        "        return report\n",
        "    \n",
        "    def create_inference_visualizations(self, results, model_name):\n",
        "        \"\"\"Create inference visualizations and upload directly to S3\"\"\"\n",
        "        logger.info(f\"üìä Creating {model_name} inference visualizations...\")\n",
        "        \n",
        "        try:\n",
        "            s3_manager = get_s3_manager()\n",
        "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "            \n",
        "            if model_name == 'revenue':\n",
        "                # Predicted revenue distribution\n",
        "                fig1 = px.histogram(\n",
        "                    results, x='predicted_revenue',\n",
        "                    title=f'{model_name.replace(\"_\", \" \").title()} Predicted Revenue Distribution',\n",
        "                    labels={'predicted_revenue': 'Predicted Revenue', 'count': 'Customer Count'}\n",
        "                )\n",
        "                \n",
        "                # Revenue category distribution\n",
        "                fig2 = px.pie(\n",
        "                    values=results['revenue_category'].value_counts().values,\n",
        "                    names=results['revenue_category'].value_counts().index,\n",
        "                    title=f'{model_name.replace(\"_\", \" \").title()} Revenue Category Distribution'\n",
        "                )\n",
        "                \n",
        "                # Upload visualizations directly to S3\n",
        "                html1_key = f'models/forecasting/inference_results/{model_name}_revenue_distribution_{timestamp}.html'\n",
        "                html2_key = f'models/forecasting/inference_results/{model_name}_revenue_categories_{timestamp}.html'\n",
        "                \n",
        "            elif model_name == 'ctr':\n",
        "                # Predicted CTR distribution\n",
        "                fig1 = px.histogram(\n",
        "                    results, x='predicted_ctr',\n",
        "                    title=f'{model_name.replace(\"_\", \" \").title()} Predicted CTR Distribution',\n",
        "                    labels={'predicted_ctr': 'Predicted CTR', 'count': 'Customer Count'}\n",
        "                )\n",
        "                \n",
        "                # CTR category distribution\n",
        "                fig2 = px.pie(\n",
        "                    values=results['ctr_category'].value_counts().values,\n",
        "                    names=results['ctr_category'].value_counts().index,\n",
        "                    title=f'{model_name.replace(\"_\", \" \").title()} CTR Category Distribution'\n",
        "                )\n",
        "                \n",
        "                # Upload visualizations directly to S3\n",
        "                html1_key = f'models/forecasting/inference_results/{model_name}_ctr_distribution_{timestamp}.html'\n",
        "                html2_key = f'models/forecasting/inference_results/{model_name}_ctr_categories_{timestamp}.html'\n",
        "            \n",
        "            # Convert figures to HTML and upload\n",
        "            html1_bytes = fig1.to_html().encode('utf-8')\n",
        "            html2_bytes = fig2.to_html().encode('utf-8')\n",
        "            \n",
        "            s3_manager.upload_bytes_direct(html1_bytes, html1_key, 'text/html')\n",
        "            s3_manager.upload_bytes_direct(html2_bytes, html2_key, 'text/html')\n",
        "            \n",
        "            logger.info(f\"‚úÖ {model_name} visualizations uploaded directly to S3\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            logger.error(f\"‚ùå Failed to create {model_name} visualizations: {e}\")\n",
        "    \n",
        "    def run_batch_inference(self, data_path=None, models=None):\n",
        "        \"\"\"Run batch inference for all models\"\"\"\n",
        "        logger.info(\"üöÄ Starting Forecasting Batch Inference...\")\n",
        "        \n",
        "        try:\n",
        "            # Load models\n",
        "            self.load_trained_models()\n",
        "            \n",
        "            # Load data\n",
        "            df = self.load_inference_data(data_path)\n",
        "            if df is None:\n",
        "                raise Exception(\"Failed to load inference data\")\n",
        "            \n",
        "            # Determine which models to run\n",
        "            if models is None:\n",
        "                models = list(self.models.keys())\n",
        "            \n",
        "            all_results = {}\n",
        "            \n",
        "            for model_name in models:\n",
        "                if model_name not in self.models:\n",
        "                    logger.warning(f\"‚ö†Ô∏è Model {model_name} not found, skipping...\")\n",
        "                    continue\n",
        "                \n",
        "                # Prepare features\n",
        "                df_features = self.prepare_features(df, model_name)\n",
        "                \n",
        "                if df_features is None or len(df_features) == 0:\n",
        "                    logger.warning(f\"‚ö†Ô∏è  No features prepared for {model_name}, skipping...\")\n",
        "                    continue\n",
        "                \n",
        "                # Perform inference\n",
        "                if model_name == 'revenue':\n",
        "                    results = self.perform_revenue_forecasting(df_features)\n",
        "                elif model_name == 'ctr':\n",
        "                    results = self.perform_ctr_forecasting(df_features)\n",
        "                else:\n",
        "                    logger.warning(f\"‚ö†Ô∏è  Unknown model: {model_name}\")\n",
        "                    continue\n",
        "                \n",
        "                if results is not None:\n",
        "                    # Save results\n",
        "                    results_file, report_file = self.save_inference_results(results, model_name)\n",
        "                    \n",
        "                    # Create visualizations\n",
        "                    self.create_inference_visualizations(results, model_name)\n",
        "                    \n",
        "                    all_results[model_name] = results\n",
        "                    \n",
        "                    logger.info(f\"‚úÖ {model_name} batch inference completed\")\n",
        "            \n",
        "            logger.info(\"=\" * 60)\n",
        "            logger.info(\"üéâ BATCH INFERENCE COMPLETED!\")\n",
        "            logger.info(\"=\" * 60)\n",
        "            logger.info(f\"üìä Processed {len(df)} customers\")\n",
        "            logger.info(f\"üéØ Ran inference for {len(all_results)} models\")\n",
        "            \n",
        "            return all_results\n",
        "            \n",
        "        except Exception as e:\n",
        "            logger.error(f\"‚ùå Error in batch inference: {e}\")\n",
        "            raise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run the Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:üöÄ Starting Forecasting Batch Inference...\n",
            "INFO:__main__:üì• Loading trained forecasting models...\n",
            "INFO:__main__:‚úÖ Loaded Revenue Forecasting model\n",
            "INFO:__main__:‚úÖ Loaded CTR Forecasting model\n",
            "INFO:__main__:‚úÖ Loaded 2 models\n",
            "INFO:__main__:üìä Loading recent inference data...\n",
            "INFO:__main__:üîç Loading recent inference data from S3...\n",
            "INFO:utils.s3_utils:Loading recent inference data from S3 (last 3 months)...\n",
            "INFO:utils.s3_utils:Loading data newer than 2025-06-03\n",
            "INFO:utils.s3_utils:Downloading s3://nuscale-data-services-public/amato_pm/data_pipelines/unified_dataset/output//unified_customer_dataset.parquet to data_pipelines/unified_dataset/output/unified_customer_dataset.parquet\n",
            "INFO:utils.s3_utils:Downloading s3://nuscale-data-services-public/amato_pm/data_pipelines/unified_dataset/output//unified_dataset_report.yaml to data_pipelines/unified_dataset/output/unified_dataset_report.yaml\n",
            "INFO:utils.s3_utils:Downloading s3://nuscale-data-services-public/amato_pm/data_pipelines/unified_dataset/output//unified_dataset_summary.yaml to data_pipelines/unified_dataset/output/unified_dataset_summary.yaml\n",
            "INFO:utils.s3_utils:Downloading s3://nuscale-data-services-public/amato_pm/data_pipelines/unified_dataset/output/recent_customer_dataset.parquet to data_pipelines/unified_dataset/output/recent_customer_dataset.parquet\n",
            "INFO:utils.s3_utils:Downloading s3://nuscale-data-services-public/amato_pm/data_pipelines/unified_dataset/output/timeline_datasets_metadata.yaml to data_pipelines/unified_dataset/output/timeline_datasets_metadata.yaml\n",
            "INFO:utils.s3_utils:Downloading s3://nuscale-data-services-public/amato_pm/data_pipelines/unified_dataset/output/unified_customer_dataset.parquet to data_pipelines/unified_dataset/output/unified_customer_dataset.parquet\n",
            "INFO:utils.s3_utils:Downloading s3://nuscale-data-services-public/amato_pm/data_pipelines/unified_dataset/output/unified_dataset_report.yaml to data_pipelines/unified_dataset/output/unified_dataset_report.yaml\n",
            "INFO:utils.s3_utils:Downloading s3://nuscale-data-services-public/amato_pm/data_pipelines/unified_dataset/output/unified_dataset_summary.yaml to data_pipelines/unified_dataset/output/unified_dataset_summary.yaml\n",
            "INFO:__main__:‚úÖ Recent inference data loaded from S3\n",
            "INFO:__main__:‚úÖ Loaded recent inference data: 1196 customers\n",
            "INFO:__main__:ÔøΩÔøΩ Preparing features for revenue inference...\n",
            "INFO:__main__:‚úÖ Prepared 1196 customers with 5 features for revenue\n",
            "INFO:__main__:üéØ Performing revenue forecasting inference...\n",
            "INFO:__main__:‚úÖ Revenue forecasting completed: 1196 predictions\n",
            "INFO:__main__:üíæ Saving revenue inference results...\n",
            "INFO:utils.s3_utils:Uploading bytes directly to s3://nuscale-data-services-public/models/forecasting/inference_results/revenue_inference_results_20250901_231733.parquet\n",
            "INFO:utils.s3_utils:Successfully uploaded bytes to s3://nuscale-data-services-public/models/forecasting/inference_results/revenue_inference_results_20250901_231733.parquet\n",
            "INFO:__main__:üìã Generating revenue inference report...\n",
            "INFO:utils.s3_utils:Uploading bytes directly to s3://nuscale-data-services-public/models/forecasting/inference_results/revenue_inference_report_20250901_231733.yaml\n",
            "INFO:utils.s3_utils:Successfully uploaded bytes to s3://nuscale-data-services-public/models/forecasting/inference_results/revenue_inference_report_20250901_231733.yaml\n",
            "INFO:__main__:‚úÖ revenue results uploaded directly to S3\n",
            "INFO:__main__:üìä Creating revenue inference visualizations...\n",
            "INFO:utils.s3_utils:Uploading bytes directly to s3://nuscale-data-services-public/models/forecasting/inference_results/revenue_revenue_distribution_20250901_231733.html\n",
            "INFO:utils.s3_utils:Successfully uploaded bytes to s3://nuscale-data-services-public/models/forecasting/inference_results/revenue_revenue_distribution_20250901_231733.html\n",
            "INFO:utils.s3_utils:Uploading bytes directly to s3://nuscale-data-services-public/models/forecasting/inference_results/revenue_revenue_categories_20250901_231733.html\n",
            "INFO:utils.s3_utils:Successfully uploaded bytes to s3://nuscale-data-services-public/models/forecasting/inference_results/revenue_revenue_categories_20250901_231733.html\n",
            "INFO:__main__:‚úÖ revenue visualizations uploaded directly to S3\n",
            "INFO:__main__:‚úÖ revenue batch inference completed\n",
            "INFO:__main__:ÔøΩÔøΩ Preparing features for ctr inference...\n",
            "INFO:__main__:‚úÖ Prepared 1196 customers with 5 features for ctr\n",
            "INFO:__main__:üéØ Performing CTR forecasting inference...\n",
            "INFO:__main__:‚úÖ CTR forecasting completed: 1196 predictions\n",
            "INFO:__main__:üíæ Saving ctr inference results...\n",
            "INFO:utils.s3_utils:Uploading bytes directly to s3://nuscale-data-services-public/models/forecasting/inference_results/ctr_inference_results_20250901_231738.parquet\n",
            "INFO:utils.s3_utils:Successfully uploaded bytes to s3://nuscale-data-services-public/models/forecasting/inference_results/ctr_inference_results_20250901_231738.parquet\n",
            "INFO:__main__:üìã Generating ctr inference report...\n",
            "INFO:utils.s3_utils:Uploading bytes directly to s3://nuscale-data-services-public/models/forecasting/inference_results/ctr_inference_report_20250901_231738.yaml\n",
            "INFO:utils.s3_utils:Successfully uploaded bytes to s3://nuscale-data-services-public/models/forecasting/inference_results/ctr_inference_report_20250901_231738.yaml\n",
            "INFO:__main__:‚úÖ ctr results uploaded directly to S3\n",
            "INFO:__main__:üìä Creating ctr inference visualizations...\n",
            "INFO:utils.s3_utils:Uploading bytes directly to s3://nuscale-data-services-public/models/forecasting/inference_results/ctr_ctr_distribution_20250901_231739.html\n",
            "INFO:utils.s3_utils:Successfully uploaded bytes to s3://nuscale-data-services-public/models/forecasting/inference_results/ctr_ctr_distribution_20250901_231739.html\n",
            "INFO:utils.s3_utils:Uploading bytes directly to s3://nuscale-data-services-public/models/forecasting/inference_results/ctr_ctr_categories_20250901_231739.html\n",
            "INFO:utils.s3_utils:Successfully uploaded bytes to s3://nuscale-data-services-public/models/forecasting/inference_results/ctr_ctr_categories_20250901_231739.html\n",
            "INFO:__main__:‚úÖ ctr visualizations uploaded directly to S3\n",
            "INFO:__main__:‚úÖ ctr batch inference completed\n",
            "INFO:__main__:============================================================\n",
            "INFO:__main__:üéâ BATCH INFERENCE COMPLETED!\n",
            "INFO:__main__:============================================================\n",
            "INFO:__main__:üìä Processed 1196 customers\n",
            "INFO:__main__:üéØ Ran inference for 2 models\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üéâ Forecasting Batch Inference completed successfully!\n",
            "üìä Results saved to models/forecasting/inference_results/\n",
            "üìà Ready for revenue and CTR forecasting analysis!\n"
          ]
        }
      ],
      "source": [
        "# Initialize and run the pipeline\n",
        "if __name__ == \"__main__\":\n",
        "    inference = ForecastingBatchInference()\n",
        "    results = inference.run_batch_inference()\n",
        "    \n",
        "    print(\"\\nüéâ Forecasting Batch Inference completed successfully!\")\n",
        "    print(f\"üìä Results saved to models/forecasting/inference_results/\")\n",
        "    print(\"üìà Ready for revenue and CTR forecasting analysis!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
