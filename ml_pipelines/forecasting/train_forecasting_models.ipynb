{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AMATO Production - Forecasting ML Pipeline\n",
        "\n",
        "This notebook trains forecasting models for CTR and revenue prediction using customer behavioral data.\n",
        "\n",
        "**Author:** Data Science Team  \n",
        "**Date:** 2024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîß Using project root: /Users/priyankmavani/Desktop/apps/amato\n",
            "‚úÖ Successfully imported utils.s3_utils\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yaml\n",
        "import logging\n",
        "import os\n",
        "import sys\n",
        "import joblib\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Add project root to path for imports\n",
        "# Try multiple possible paths for Jupyter notebook compatibility\n",
        "possible_paths = [\n",
        "    Path.cwd(),  # Current working directory\n",
        "    Path.cwd().parent,  # Parent of current directory\n",
        "    Path.cwd().parent.parent,  # Grandparent of current directory\n",
        "    Path(__file__).parent.parent.parent if '__file__' in globals() else None  # If __file__ exists\n",
        "]\n",
        "\n",
        "# Filter out None values and find the one with utils folder\n",
        "project_root = None\n",
        "for path in possible_paths:\n",
        "    if path and (path / 'utils').exists():\n",
        "        project_root = path\n",
        "        break\n",
        "\n",
        "if project_root is None:\n",
        "    # Fallback: use current directory and hope for the best\n",
        "    project_root = Path.cwd()\n",
        "\n",
        "sys.path.append(str(project_root))\n",
        "print(f\"üîß Using project root: {project_root}\")\n",
        "\n",
        "try:\n",
        "    from utils.s3_utils import get_s3_manager\n",
        "    print(\"‚úÖ Successfully imported utils.s3_utils\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Failed to import utils.s3_utils: {e}\")\n",
        "    print(\"üîß Trying alternative import...\")\n",
        "    try:\n",
        "        # Try relative import\n",
        "        sys.path.append('.')\n",
        "        from utils.s3_utils import get_s3_manager\n",
        "        print(\"‚úÖ Successfully imported with relative path\")\n",
        "    except ImportError as e2:\n",
        "        print(f\"‚ùå Alternative import also failed: {e2}\")\n",
        "        raise\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Forecasting Pipeline Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ForecastingPipeline:\n",
        "    def __init__(self):\n",
        "        self.models = {}\n",
        "        self.scalers = {}\n",
        "        self.metadata = {}\n",
        "        \n",
        "    def load_data(self):\n",
        "        \"\"\"Load customer data for forecasting from S3\"\"\"\n",
        "        try:\n",
        "            # Load historical training data from S3\n",
        "            logger.info(\"üîç Loading historical training data from S3...\")\n",
        "            s3_manager = get_s3_manager()\n",
        "            s3_manager.load_inference_data_from_s3()\n",
        "            logger.info(\"‚úÖ Historical training data loaded from S3\")\n",
        "            \n",
        "            # Load the historical dataset\n",
        "            data_path = 'data_pipelines/unified_dataset/output/unified_customer_dataset.parquet'\n",
        "            if os.path.exists(data_path):\n",
        "                df = pd.read_parquet(data_path)\n",
        "                logger.info(f\"‚úÖ Loaded historical training dataset: {df.shape}\")\n",
        "                return df\n",
        "            else:\n",
        "                logger.error(f\"‚ùå Historical training dataset not found at {data_path}\")\n",
        "                return None\n",
        "        except Exception as e:\n",
        "            logger.error(f\"‚ùå Failed to load data: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def prepare_features(self, df, target_col):\n",
        "        \"\"\"Prepare features for forecasting\"\"\"\n",
        "        logger.info(f\"üîß Preparing features for {target_col} forecasting...\")\n",
        "        \n",
        "        # Select features based on target\n",
        "        if target_col == 'ctr':\n",
        "            feature_columns = [\n",
        "                'recency_days', 'frequency', 'monetary_value',\n",
        "                'avg_order_value', 'total_orders', 'days_since_first_order',\n",
        "                'customer_lifetime_value', 'avg_days_between_orders',\n",
        "                'order_count_30d', 'order_count_90d', 'order_count_365d',\n",
        "                'revenue_30d', 'revenue_90d', 'revenue_365d'\n",
        "            ]\n",
        "        elif target_col == 'revenue':\n",
        "            feature_columns = [\n",
        "                'recency_days', 'frequency', 'monetary_value',\n",
        "                'avg_order_value', 'total_orders', 'days_since_first_order',\n",
        "                'customer_lifetime_value', 'avg_days_between_orders',\n",
        "                'order_count_30d', 'order_count_90d', 'order_count_365d',\n",
        "                'revenue_30d', 'revenue_90d', 'revenue_365d'\n",
        "            ]\n",
        "        else:\n",
        "            logger.error(f\"‚ùå Unknown target column: {target_col}\")\n",
        "            return None, None, None\n",
        "        \n",
        "        # Filter available features\n",
        "        available_features = [col for col in feature_columns if col in df.columns]\n",
        "        \n",
        "        if len(available_features) < 5:\n",
        "            logger.warning(f\"‚ö†Ô∏è  Only {len(available_features)} features available for {target_col}\")\n",
        "            \n",
        "        # Create feature matrix\n",
        "        X = df[available_features].copy()\n",
        "        \n",
        "        # Create synthetic target variables based on available data\n",
        "        if target_col == 'revenue':\n",
        "            # Create revenue forecasting target based on monetary value and frequency\n",
        "            y = df.apply(lambda row: \n",
        "                row['monetary_value'] * (1 + row['frequency'] / 10), axis=1)\n",
        "        elif target_col == 'ctr':\n",
        "            # Create CTR forecasting target based on engagement metrics\n",
        "            y = df.apply(lambda row: \n",
        "                min(0.15, max(0.01, 0.05 * (1 + row['frequency'] / 10))), axis=1)\n",
        "        else:\n",
        "            y = None\n",
        "        \n",
        "        # Handle missing values\n",
        "        X = X.fillna(X.median())\n",
        "        if y is not None:\n",
        "            y = y.fillna(y.median())\n",
        "        \n",
        "        # Remove outliers using IQR method\n",
        "        for col in X.columns:\n",
        "            Q1 = X[col].quantile(0.25)\n",
        "            Q3 = X[col].quantile(0.75)\n",
        "            IQR = Q3 - Q1\n",
        "            lower_bound = Q1 - 1.5 * IQR\n",
        "            upper_bound = Q3 + 1.5 * IQR\n",
        "            X[col] = X[col].clip(lower_bound, upper_bound)\n",
        "        \n",
        "        logger.info(f\"‚úÖ Prepared {len(X)} customers with {len(X.columns)} features for {target_col}\")\n",
        "        return X, y, available_features\n",
        "    \n",
        "    def train_ctr_model(self, X, y, n_estimators=100, max_depth=10):\n",
        "        \"\"\"Train CTR forecasting model\"\"\"\n",
        "        logger.info(f\"üéØ Training CTR forecasting model...\")\n",
        "        \n",
        "        # Split data\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "        \n",
        "        # Scale features\n",
        "        scaler = StandardScaler()\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "        X_test_scaled = scaler.transform(X_test)\n",
        "        \n",
        "        # Train Random Forest model\n",
        "        model = RandomForestRegressor(\n",
        "            n_estimators=n_estimators,\n",
        "            max_depth=max_depth,\n",
        "            random_state=42,\n",
        "            n_jobs=-1\n",
        "        )\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "        \n",
        "        # Make predictions\n",
        "        y_pred = model.predict(X_test_scaled)\n",
        "        \n",
        "        # Calculate metrics\n",
        "        mse = mean_squared_error(y_test, y_pred)\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "        \n",
        "        # Cross-validation score\n",
        "        cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='r2')\n",
        "        \n",
        "        logger.info(f\"‚úÖ CTR forecasting training completed\")\n",
        "        logger.info(f\"   MSE: {mse:.6f}\")\n",
        "        logger.info(f\"   MAE: {mae:.6f}\")\n",
        "        logger.info(f\"   R¬≤: {r2:.4f}\")\n",
        "        logger.info(f\"   CV R¬≤: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
        "        \n",
        "        return model, scaler, {\n",
        "            'mse': mse,\n",
        "            'mae': mae,\n",
        "            'r2': r2,\n",
        "            'cv_r2_mean': cv_scores.mean(),\n",
        "            'cv_r2_std': cv_scores.std(),\n",
        "            'n_estimators': n_estimators,\n",
        "            'max_depth': max_depth\n",
        "        }\n",
        "    \n",
        "    def train_revenue_model(self, X, y, n_estimators=100, max_depth=10):\n",
        "        \"\"\"Train revenue forecasting model\"\"\"\n",
        "        logger.info(f\"üéØ Training revenue forecasting model...\")\n",
        "        \n",
        "        # Split data\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "        \n",
        "        # Scale features\n",
        "        scaler = StandardScaler()\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "        X_test_scaled = scaler.transform(X_test)\n",
        "        \n",
        "        # Train Random Forest model\n",
        "        model = RandomForestRegressor(\n",
        "            n_estimators=n_estimators,\n",
        "            max_depth=max_depth,\n",
        "            random_state=42,\n",
        "            n_jobs=-1\n",
        "        )\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "        \n",
        "        # Make predictions\n",
        "        y_pred = model.predict(X_test_scaled)\n",
        "        \n",
        "        # Calculate metrics\n",
        "        mse = mean_squared_error(y_test, y_pred)\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "        \n",
        "        # Cross-validation score\n",
        "        cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='r2')\n",
        "        \n",
        "        logger.info(f\"‚úÖ Revenue forecasting training completed\")\n",
        "        logger.info(f\"   MSE: {mse:.6f}\")\n",
        "        logger.info(f\"   MAE: {mae:.6f}\")\n",
        "        logger.info(f\"   R¬≤: {r2:.4f}\")\n",
        "        logger.info(f\"   CV R¬≤: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
        "        \n",
        "        return model, scaler, {\n",
        "            'mse': mse,\n",
        "            'mae': mae,\n",
        "            'r2': r2,\n",
        "            'cv_r2_mean': cv_scores.mean(),\n",
        "            'cv_r2_std': cv_scores.std(),\n",
        "            'n_estimators': n_estimators,\n",
        "            'max_depth': max_depth\n",
        "        }\n",
        "    \n",
        "    def save_models(self, ctr_model, ctr_scaler, revenue_model, revenue_scaler, \n",
        "                    ctr_metrics, revenue_metrics, feature_names):\n",
        "        \"\"\"Save trained models and metadata\"\"\"\n",
        "        logger.info(\"üíæ Saving trained models...\")\n",
        "        \n",
        "        # Create output directory\n",
        "        output_dir = 'models/forecasting'\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        \n",
        "        # Save CTR model\n",
        "        ctr_path = os.path.join(output_dir, 'ctr_forecasting_model.pkl')\n",
        "        joblib.dump(ctr_model, ctr_path)\n",
        "        \n",
        "        # Save CTR scaler\n",
        "        ctr_scaler_path = os.path.join(output_dir, 'ctr_forecasting_scaler.pkl')\n",
        "        joblib.dump(ctr_scaler, ctr_scaler_path)\n",
        "        \n",
        "        # Save revenue model\n",
        "        revenue_path = os.path.join(output_dir, 'revenue_forecasting_model.pkl')\n",
        "        joblib.dump(revenue_model, revenue_path)\n",
        "        \n",
        "        # Save revenue scaler\n",
        "        revenue_scaler_path = os.path.join(output_dir, 'revenue_forecasting_scaler.pkl')\n",
        "        joblib.dump(revenue_scaler, revenue_scaler_path)\n",
        "        \n",
        "        # Save metadata\n",
        "        metadata = {\n",
        "            'ctr': ctr_metrics,\n",
        "            'revenue': revenue_metrics,\n",
        "            'feature_names': feature_names,\n",
        "            'training_date': datetime.now().isoformat(),\n",
        "            'model_versions': {\n",
        "                'ctr': '1.0',\n",
        "                'revenue': '1.0'\n",
        "            }\n",
        "        }\n",
        "        \n",
        "        metadata_path = os.path.join(output_dir, 'pipeline_report.yaml')\n",
        "        with open(metadata_path, 'w') as f:\n",
        "            yaml.dump(metadata, f, default_flow_style=False)\n",
        "        \n",
        "        # Upload to S3\n",
        "        try:\n",
        "            s3_manager = get_s3_manager()\n",
        "            s3_manager.upload_file(ctr_path, \"amato_pm/models/forecasting\")\n",
        "            s3_manager.upload_file(ctr_scaler_path, \"amato_pm/models/forecasting\")\n",
        "            s3_manager.upload_file(revenue_path, \"amato_pm/models/forecasting\")\n",
        "            s3_manager.upload_file(revenue_scaler_path, \"amato_pm/models/forecasting\")\n",
        "            s3_manager.upload_file(metadata_path, \"amato_pm/models/forecasting\")\n",
        "            logger.info(\"‚úÖ Models uploaded to S3\")\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"‚ö†Ô∏è  Failed to upload models to S3: {e}\")\n",
        "        \n",
        "        logger.info(f\"‚úÖ Models saved to {output_dir}\")\n",
        "        return output_dir\n",
        "    \n",
        "    def run_training_pipeline(self):\n",
        "        \"\"\"Run the complete forecasting training pipeline\"\"\"\n",
        "        logger.info(\"üöÄ Starting Forecasting Training Pipeline...\")\n",
        "        \n",
        "        try:\n",
        "            # Load data\n",
        "            df = self.load_data()\n",
        "            if df is None:\n",
        "                raise Exception(\"Failed to load data\")\n",
        "            \n",
        "            # Prepare features for CTR forecasting\n",
        "            X_ctr, y_ctr, ctr_features = self.prepare_features(df, 'ctr')\n",
        "            if X_ctr is None:\n",
        "                raise Exception(\"Failed to prepare CTR features\")\n",
        "            \n",
        "            # Prepare features for revenue forecasting\n",
        "            X_revenue, y_revenue, revenue_features = self.prepare_features(df, 'revenue')\n",
        "            if X_revenue is None:\n",
        "                raise Exception(\"Failed to prepare revenue features\")\n",
        "            \n",
        "            # Train CTR model\n",
        "            ctr_model, ctr_scaler, ctr_metrics = self.train_ctr_model(X_ctr, y_ctr)\n",
        "            \n",
        "            # Train revenue model\n",
        "            revenue_model, revenue_scaler, revenue_metrics = self.train_revenue_model(X_revenue, y_revenue)\n",
        "            \n",
        "            # Save models\n",
        "            output_dir = self.save_models(\n",
        "                ctr_model, ctr_scaler, revenue_model, revenue_scaler,\n",
        "                ctr_metrics, revenue_metrics, {\n",
        "                    'ctr': ctr_features,\n",
        "                    'revenue': revenue_features\n",
        "                }\n",
        "            )\n",
        "            \n",
        "            logger.info(\"=\" * 60)\n",
        "            logger.info(\"üéâ FORECASTING TRAINING COMPLETED!\")\n",
        "            logger.info(\"=\" * 60)\n",
        "            logger.info(f\"üìä Trained 2 models on {len(df)} customers\")\n",
        "            logger.info(f\"üîß CTR features: {len(ctr_features)}, Revenue features: {len(revenue_features)}\")\n",
        "            logger.info(f\"üíæ Models saved to: {output_dir}\")\n",
        "            \n",
        "            return {\n",
        "                'ctr': ctr_model,\n",
        "                'revenue': revenue_model,\n",
        "                'ctr_metrics': ctr_metrics,\n",
        "                'revenue_metrics': revenue_metrics\n",
        "            }\n",
        "            \n",
        "        except Exception as e:\n",
        "            logger.error(f\"‚ùå Error in training pipeline: {e}\")\n",
        "            raise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run the Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:üöÄ Starting Forecasting Training Pipeline...\n",
            "INFO:__main__:üîç Loading historical training data from S3...\n",
            "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
            "INFO:utils.s3_utils:Loading recent inference data from S3 with smart caching (last 3 months)...\n",
            "INFO:utils.s3_utils:Loading data newer than 2025-06-06\n",
            "INFO:utils.s3_utils:Downloading s3://nuscale-data-services-public/amato_pm/data_pipelines/unified_dataset/output/recent_customer_dataset.parquet to data_pipelines/unified_dataset/output/recent_customer_dataset.parquet\n",
            "INFO:utils.s3_utils:Downloading s3://nuscale-data-services-public/amato_pm/data_pipelines/unified_dataset/output/timeline_datasets_metadata.yaml to data_pipelines/unified_dataset/output/timeline_datasets_metadata.yaml\n",
            "INFO:utils.s3_utils:Downloading s3://nuscale-data-services-public/amato_pm/data_pipelines/unified_dataset/output/unified_customer_dataset.parquet to data_pipelines/unified_dataset/output/unified_customer_dataset.parquet\n",
            "INFO:__main__:‚úÖ Historical training data loaded from S3\n",
            "INFO:__main__:‚úÖ Loaded historical training dataset: (8514, 89)\n",
            "INFO:__main__:üîß Preparing features for ctr forecasting...\n",
            "INFO:__main__:‚úÖ Prepared 8514 customers with 5 features for ctr\n",
            "INFO:__main__:üîß Preparing features for revenue forecasting...\n",
            "INFO:__main__:‚úÖ Prepared 8514 customers with 5 features for revenue\n",
            "INFO:__main__:üéØ Training CTR forecasting model...\n",
            "INFO:__main__:‚úÖ CTR forecasting training completed\n",
            "INFO:__main__:   MSE: 0.000000\n",
            "INFO:__main__:   MAE: 0.000018\n",
            "INFO:__main__:   R¬≤: 0.9988\n",
            "INFO:__main__:   CV R¬≤: 0.9991 (+/- 0.0013)\n",
            "INFO:__main__:üéØ Training revenue forecasting model...\n",
            "INFO:__main__:‚úÖ Revenue forecasting training completed\n",
            "INFO:__main__:   MSE: 550400.024112\n",
            "INFO:__main__:   MAE: 72.360428\n",
            "INFO:__main__:   R¬≤: 0.9842\n",
            "INFO:__main__:   CV R¬≤: 0.9912 (+/- 0.0093)\n",
            "INFO:__main__:üíæ Saving trained models...\n",
            "INFO:utils.s3_utils:Uploading models/forecasting/ctr_forecasting_model.pkl to s3://nuscale-data-services-public/amato_pm/amato_pm/models/forecasting/ctr_forecasting_model.pkl\n",
            "INFO:utils.s3_utils:Successfully uploaded models/forecasting/ctr_forecasting_model.pkl\n",
            "INFO:utils.s3_utils:Uploading models/forecasting/ctr_forecasting_scaler.pkl to s3://nuscale-data-services-public/amato_pm/amato_pm/models/forecasting/ctr_forecasting_scaler.pkl\n",
            "INFO:utils.s3_utils:Successfully uploaded models/forecasting/ctr_forecasting_scaler.pkl\n",
            "INFO:utils.s3_utils:Uploading models/forecasting/revenue_forecasting_model.pkl to s3://nuscale-data-services-public/amato_pm/amato_pm/models/forecasting/revenue_forecasting_model.pkl\n",
            "INFO:utils.s3_utils:Successfully uploaded models/forecasting/revenue_forecasting_model.pkl\n",
            "INFO:utils.s3_utils:Uploading models/forecasting/revenue_forecasting_scaler.pkl to s3://nuscale-data-services-public/amato_pm/amato_pm/models/forecasting/revenue_forecasting_scaler.pkl\n",
            "INFO:utils.s3_utils:Successfully uploaded models/forecasting/revenue_forecasting_scaler.pkl\n",
            "INFO:utils.s3_utils:Uploading models/forecasting/pipeline_report.yaml to s3://nuscale-data-services-public/amato_pm/amato_pm/models/forecasting/pipeline_report.yaml\n",
            "INFO:utils.s3_utils:Successfully uploaded models/forecasting/pipeline_report.yaml\n",
            "INFO:__main__:‚úÖ Models uploaded to S3\n",
            "INFO:__main__:‚úÖ Models saved to models/forecasting\n",
            "INFO:__main__:============================================================\n",
            "INFO:__main__:üéâ FORECASTING TRAINING COMPLETED!\n",
            "INFO:__main__:============================================================\n",
            "INFO:__main__:üìä Trained 2 models on 8514 customers\n",
            "INFO:__main__:üîß CTR features: 5, Revenue features: 5\n",
            "INFO:__main__:üíæ Models saved to: models/forecasting\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üéâ Forecasting Training completed successfully!\n",
            "üìä CTR: R¬≤ = 0.9988, CV R¬≤ = 0.9991\n",
            "üìä Revenue: R¬≤ = 0.9842, CV R¬≤ = 0.9912\n",
            "üíæ Models saved and ready for inference!\n"
          ]
        }
      ],
      "source": [
        "# Initialize and run the pipeline\n",
        "if __name__ == \"__main__\":\n",
        "    pipeline = ForecastingPipeline()\n",
        "    results = pipeline.run_training_pipeline()\n",
        "    \n",
        "    print(\"\\nüéâ Forecasting Training completed successfully!\")\n",
        "    print(f\"üìä CTR: R¬≤ = {results['ctr_metrics']['r2']:.4f}, CV R¬≤ = {results['ctr_metrics']['cv_r2_mean']:.4f}\")\n",
        "    print(f\"üìä Revenue: R¬≤ = {results['revenue_metrics']['r2']:.4f}, CV R¬≤ = {results['revenue_metrics']['cv_r2_mean']:.4f}\")\n",
        "    print(\"üíæ Models saved and ready for inference!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
